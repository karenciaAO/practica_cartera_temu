{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c536c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: pyxlsb in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (1.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/karenaraque/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyxlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fd548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99bad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataFramePrueba', 'diccionario']\n",
      "Shape: (146939, 30)\n",
      "\n",
      "Tipos de datos:\n",
      "IdentificadorCliente                        int64\n",
      "FechaEvento                                object\n",
      "UsabilidadCupo                             object\n",
      "CategoriaPrincipalCredito                  object\n",
      "DiasMaximosMoraCreditosGenerados          float64\n",
      "NumeroCreditosGPrevius                    float64\n",
      "NumeroCreditosGCanalFPrevius              float64\n",
      "NumeroCreditosGEstadoActivosPrevius       float64\n",
      "NumeroCreditosGEstadoPagadosPrevius       float64\n",
      "NumeroCreditosGCanalVPrevius              float64\n",
      "NumeroCreditosLPrevius                    float64\n",
      "NumeroCreditosLEstadoActivosPrevius       float64\n",
      "NumeroCreditosLEstadoPagadosPrevius       float64\n",
      "FechaVinculacionCliente                   float64\n",
      "FechaPrimerUso                            float64\n",
      "FechaUltimoUso                            float64\n",
      "TotalPagosEfectuadosGlobalmentePrevius    float64\n",
      "TotalPagosEfectuadosLocalmentePrevius     float64\n",
      "CodigoAlmacenEntregaTC                     object\n",
      "CodigoMunicipioEntregaTC                  float64\n",
      "TipoMunicipioEntregaTC                     object\n",
      "CanalMunicipioEntregaTC                    object\n",
      "NumeroIntentosFallidos                    float64\n",
      "CupoAprobado                              float64\n",
      "UsoAppWeb                                  object\n",
      "ScoreCrediticio                           float64\n",
      "Genero                                     object\n",
      "Edad                                      float64\n",
      "DiasMora                                    int64\n",
      "PerdidaCartera                              int64\n",
      "dtype: object\n",
      "\n",
      "IdentificadorCliente — 146939 valores únicos\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "\n",
      "FechaEvento — 146939 valores únicos\n",
      "['2022-09-19T13:25:31.867Z' '2023-08-23T11:33:46.417Z'\n",
      " '2022-10-01T14:59:48.920Z' '2022-09-22T21:25:09.187Z'\n",
      " '2023-03-19T17:48:52.310Z' '2022-11-10T22:14:06.450Z'\n",
      " '2022-12-04T21:33:38.130Z' '2022-06-23T09:44:55.610Z'\n",
      " '2022-10-01T13:32:38.053Z' '2023-09-26T13:59:00.617Z'\n",
      " '2023-07-12T12:09:24.737Z' '2022-05-31T09:22:36.477Z'\n",
      " '2022-05-11T15:22:39.510Z' '2023-08-31T18:23:56.993Z'\n",
      " '2022-10-01T22:10:17.433Z']\n",
      "\n",
      "UsabilidadCupo — 107705 valores únicos\n",
      "['0.1184320077740548479' '0.0771590000000000000' '0.1855666666666666667'\n",
      " 'null' '0.4752148710773535878' '0.1561200000000000000'\n",
      " '0.5927940000000000000' '0.8576124728323314114' '0.2435427485988745499'\n",
      " '0.9671000000000000000' '0.1248160000000000000' '0.3081000000000000000'\n",
      " '0.1855000000000000000' '0.0732485183968226177' '0.1845000000000000000']\n",
      "\n",
      "CategoriaPrincipalCredito — 32 valores únicos\n",
      "[nan 'hogar-y-muebles' 'computacion' 'belleza-y-cuidado-personal'\n",
      " 'electronica,-audio-y-video' 'celulares-y-telefonos'\n",
      " 'instrumentos-musicales-2' 'electrodomesticos' 'animales-y-mascotas'\n",
      " 'pines-virtuales' 'ropa-y-accesorios' 'herramientas-y-construccion'\n",
      " 'salud-y-equipamiento-medico' 'accesorios-para-vehiculos'\n",
      " 'alimentos-y-bebidas']\n",
      "\n",
      "DiasMaximosMoraCreditosGenerados — 1767 valores únicos\n",
      "[  0.  nan 129.  49.  31. 141. 122.  78.  66. 266. 140.  68. 101. 113.\n",
      "  72.]\n",
      "\n",
      "NumeroCreditosGPrevius — 208 valores únicos\n",
      "[ 9.  5. 33.  3.  4. 18.  2. 12. 14.  7. 30. 29. 40. 16.  1.]\n",
      "\n",
      "NumeroCreditosGCanalFPrevius — 207 valores únicos\n",
      "[ 9.  4. 33.  3. 18.  2. 11. 14.  7. 30. 29. 16.  1. 17. 27.]\n",
      "\n",
      "NumeroCreditosGEstadoActivosPrevius — 27 valores únicos\n",
      "[ 0.  1.  7.  3.  5.  9. nan  6.  2.  4. 11. 15.  8. 12. 13.]\n",
      "\n",
      "NumeroCreditosGEstadoPagadosPrevius — 207 valores únicos\n",
      "[ 9.  4. 33.  3. 18.  2. 12. 14.  7. 30. 29. 39. 16.  1. 11.]\n",
      "\n",
      "NumeroCreditosGCanalVPrevius — 43 valores únicos\n",
      "[ 0.  1.  7.  4.  2.  6.  3.  5. nan 13. 10.  8.  9. 35. 24.]\n",
      "\n",
      "NumeroCreditosLPrevius — 32 valores únicos\n",
      "[ 0.  1.  3.  2. nan  5.  8.  4.  7.  6. 16. 10. 11. 12. 18.]\n",
      "\n",
      "NumeroCreditosLEstadoActivosPrevius — 10 valores únicos\n",
      "[ 0.  1. nan  2.  6.  3.  5.  4. 13.  9.]\n",
      "\n",
      "NumeroCreditosLEstadoPagadosPrevius — 25 valores únicos\n",
      "[ 0.  1.  2. nan  5.  3.  4.  6. 14.  7.  9.  8. 11. 12. 19.]\n",
      "\n",
      "FechaVinculacionCliente — 3117 valores únicos\n",
      "[43719. 45157. 43545. 44688. 44496. 40189. 44792. 40382. 44171. 45193.\n",
      " 44670. 40177. 40301. 40145. 40508.]\n",
      "\n",
      "FechaPrimerUso — 4895 valores únicos\n",
      "[39065. 39650. 39541. 40019. 44496. 40196. 39075. 40382. 39612. 39806.\n",
      " 39552. 40177. 39617. 39796. 39983.]\n",
      "\n",
      "FechaUltimoUso — 2202 valores únicos\n",
      "[44765. 45158. 44830. 44716. 44807. 44864. 39146. 44692. 44780. 39924.\n",
      " 45111. 44658. 44585. 45128. 44490.]\n",
      "\n",
      "TotalPagosEfectuadosGlobalmentePrevius — 512 valores únicos\n",
      "[ 31.  22. 134.   9.  10.  32.  58.  57.   4.  19.  91. 104. 136.  67.\n",
      "   3.]\n",
      "\n",
      "TotalPagosEfectuadosLocalmentePrevius — 58 valores únicos\n",
      "[ 0.  1.  3.  7.  4. 12.  2. 14. nan  6. 26.  5.  9.  8. 11.]\n",
      "\n",
      "CodigoAlmacenEntregaTC — 83156 valores únicos\n",
      "[316 400688 3325 340786 87061 202 11609 750 164177 596199 12560 1948 1430\n",
      " 1757 1048]\n",
      "\n",
      "CodigoMunicipioEntregaTC — 438 valores únicos\n",
      "[  1.   2.  88.   4.  -1.   3.  63.  nan 130.  67.  49. 136.  46. 134.\n",
      " 135.]\n",
      "\n",
      "TipoMunicipioEntregaTC — 8 valores únicos\n",
      "['PRINCIPAL' 'INTERMEDIO' 'PEQUEÃ‘O' 'GRANDE' 'VIRTUAL' 'POBLADO' nan\n",
      " 'RURAL']\n",
      "\n",
      "CanalMunicipioEntregaTC — 3 valores únicos\n",
      "['Fisico' 'Virtual' nan]\n",
      "\n",
      "NumeroIntentosFallidos — 44 valores únicos\n",
      "[ 0.  1.  5.  3.  4.  2.  8. nan 10. 14.  6. 27. 18.  7. 30.]\n",
      "\n",
      "CupoAprobado — 115 valores únicos\n",
      "[3.0e+10 2.0e+10 5.0e+09 1.0e+10 3.0e+09 1.5e+10 4.0e+09 1.2e+10 8.0e+09\n",
      " 2.0e+09 1.6e+10 6.0e+09 1.3e+10     nan 7.0e+09]\n",
      "\n",
      "UsoAppWeb — 3 valores únicos\n",
      "[nan 'App' 'Web']\n",
      "\n",
      "ScoreCrediticio — 890 valores únicos\n",
      "[865. 726.   0. 837. 487. 616. 686. 689. 896. 598. 430. 718. 611. 849.\n",
      " 458.]\n",
      "\n",
      "Genero — 5 valores únicos\n",
      "['Femenino' 'Masculino' 'Desconocido' nan 27]\n",
      "\n",
      "Edad — 77 valores únicos\n",
      "[37. 38. 35. 34. 55. nan 33. 36. 45. 49. 71. 40. 47. 39. 57.]\n",
      "\n",
      "DiasMora — 1712 valores únicos\n",
      "[   0 1660  889 1520 1673 1373  622  847  740  161 1202 1327   90  842\n",
      " 1512]\n",
      "\n",
      "PerdidaCartera — 2 valores únicos\n",
      "[0 1]\n",
      "Duplicados: 0\n",
      "\n",
      "Porcentaje de nulos (top 10):\n",
      "TotalPagosEfectuadosLocalmentePrevius     26.6\n",
      "TotalPagosEfectuadosGlobalmentePrevius    26.6\n",
      "DiasMaximosMoraCreditosGenerados          25.8\n",
      "UsoAppWeb                                 24.5\n",
      "FechaPrimerUso                            24.4\n",
      "FechaUltimoUso                            24.4\n",
      "CategoriaPrincipalCredito                 22.3\n",
      "NumeroCreditosGCanalFPrevius              21.7\n",
      "NumeroCreditosLEstadoActivosPrevius       21.7\n",
      "NumeroCreditosGEstadoActivosPrevius       21.7\n",
      "NumeroCreditosGPrevius                    21.7\n",
      "NumeroCreditosLEstadoPagadosPrevius       21.7\n",
      "NumeroCreditosLPrevius                    21.7\n",
      "NumeroCreditosGCanalVPrevius              21.7\n",
      "NumeroCreditosGEstadoPagadosPrevius       21.7\n",
      "CodigoMunicipioEntregaTC                   1.2\n",
      "TipoMunicipioEntregaTC                     1.2\n",
      "FechaVinculacionCliente                    1.2\n",
      "Edad                                       1.1\n",
      "CupoAprobado                               0.4\n",
      "NumeroIntentosFallidos                     0.1\n",
      "ScoreCrediticio                            0.1\n",
      "CanalMunicipioEntregaTC                    0.0\n",
      "Genero                                     0.0\n",
      "DiasMora                                   0.0\n",
      "IdentificadorCliente                       0.0\n",
      "CodigoAlmacenEntregaTC                     0.0\n",
      "FechaEvento                                0.0\n",
      "UsabilidadCupo                             0.0\n",
      "PerdidaCartera                             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/karenaraque/Desktop/practica_cartera_temu/data/DataFramePrueba 2025_08.xlsb\"\n",
    "# Lista de hojas para ver cuáles tiene\n",
    "excel_hojas = pd.ExcelFile(file_path, engine=\"pyxlsb\")\n",
    "print(excel_hojas.sheet_names)\n",
    "clientes = pd.read_excel(file_path, sheet_name=\"DataFramePrueba\", engine=\"pyxlsb\")\n",
    "clientes.head(10)\n",
    "diccionario= pd.read_excel(file_path, sheet_name=\"diccionario\", engine=\"pyxlsb\")\n",
    "diccionario.head(30)\n",
    "print(\"Shape:\", clientes.shape)\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(clientes.dtypes)\n",
    "# Muestra hasta 15 valores únicos por columna\n",
    "for col in clientes.columns:\n",
    "    uniques = clientes[col].unique()\n",
    "    nuniques = len(uniques)\n",
    "    print(f\"\\n{col} — {nuniques} valores únicos\")\n",
    "    print(uniques[:15])  # muestra los primeros 15 valores distintos\n",
    "print(\"Duplicados:\", clientes.duplicated().sum())\n",
    "missing = clientes.isnull().mean().sort_values(ascending=False)\n",
    "print(\"\\nPorcentaje de nulos (top 10):\")\n",
    "print((missing*100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "751edaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SHAPE crudo: (146939, 30)\n",
      ">>> Columnas (primeras 20): ['IdentificadorCliente', 'FechaEvento', 'UsabilidadCupo', 'CategoriaPrincipalCredito', 'DiasMaximosMoraCreditosGenerados', 'NumeroCreditosGPrevius', 'NumeroCreditosGCanalFPrevius', 'NumeroCreditosGEstadoActivosPrevius', 'NumeroCreditosGEstadoPagadosPrevius', 'NumeroCreditosGCanalVPrevius', 'NumeroCreditosLPrevius', 'NumeroCreditosLEstadoActivosPrevius', 'NumeroCreditosLEstadoPagadosPrevius', 'FechaVinculacionCliente', 'FechaPrimerUso', 'FechaUltimoUso', 'TotalPagosEfectuadosGlobalmentePrevius', 'TotalPagosEfectuadosLocalmentePrevius', 'CodigoAlmacenEntregaTC', 'CodigoMunicipioEntregaTC']\n",
      "\n",
      ">>> Construyendo features (sin fuga) ...\n",
      "\n",
      "===================== EDA PREVIA (SIN FUGA) =====================\n",
      "Shape de X: (146939, 65) | y rate (1)= 0.226\n",
      "Rango de fechas (FechaEvento_dt): 2022-05-01 → 2023-10-31\n",
      "\n",
      "[Balance de clases]\n",
      "                 count    pct\n",
      "PerdidaCartera               \n",
      "no_perdida      113803  0.774\n",
      "perdida          33136  0.226\n",
      "\n",
      "[Resumen por columna] (primeras 30 filas)\n",
      "                                  columna    dtype  %nulos  n_unicos                                                      top5_valores\n",
      "                              ScoreBucket category     0.0         4 {'alto': 41836, 'medio': 40654, 'bajo': 40652, 'sin_info': 23797}\n",
      "                             CupoAprobado  float64     0.4       115                                                                {}\n",
      "                       DiasDesdeUltimoUso  float64     0.0      1096                                                                {}\n",
      "                                     Edad  float64     0.0        76                                                                {}\n",
      "                      MesesDesdePrimerUso  float64     0.0      2901                                                                {}\n",
      "                    MesesDesdeVinculacion  float64     0.0      2366                                                                {}\n",
      "             NumeroCreditosGCanalFPrevius  float64     0.0        76                                                                {}\n",
      "             NumeroCreditosGCanalVPrevius  float64     0.0         6                                                                {}\n",
      "      NumeroCreditosGEstadoActivosPrevius  float64     0.0         6                                                                {}\n",
      "      NumeroCreditosGEstadoPagadosPrevius  float64     0.0        76                                                                {}\n",
      "                   NumeroCreditosGPrevius  float64     0.0        77                                                                {}\n",
      "      NumeroCreditosLEstadoActivosPrevius  float64     0.0         2                                                                {}\n",
      "      NumeroCreditosLEstadoPagadosPrevius  float64     0.0         4                                                                {}\n",
      "                   NumeroCreditosLPrevius  float64     0.0         5                                                                {}\n",
      "                   NumeroIntentosFallidos  float64     0.0        43                                                                {}\n",
      "                          ScoreCrediticio  float64     0.0       883                                                                {}\n",
      "   TotalPagosEfectuadosGlobalmentePrevius  float64     0.0       220                                                                {}\n",
      "    TotalPagosEfectuadosLocalmentePrevius  float64     0.0        12                                                                {}\n",
      "                           UsabilidadCupo  float64     0.0    101998                                                                {}\n",
      "                   creditos_activos_ratio  float64     0.0       554                                                                {}\n",
      "                         log_CupoAprobado  float64     0.0       114                                                                {}\n",
      "                 ratio_pagos_local_global  float64     0.0      1628                                                                {}\n",
      "                    Flag_CupoAprobado_NaN    int64     0.0         2                                                                {}\n",
      "           Flag_DiasDesdeUltimoUso_Capped    int64     0.0         2                                                                {}\n",
      "              Flag_DiasDesdeUltimoUso_NaN    int64     0.0         1                                                                {}\n",
      "Flag_DiasMaximosMoraCreditosGenerados_NaN    int64     0.0         2                                                                {}\n",
      "                            Flag_Edad_NaN    int64     0.0         2                                                                {}\n",
      "                            Flag_Edad_Out    int64     0.0         2                                                                {}\n",
      "             Flag_MesesDesdePrimerUso_NaN    int64     0.0         1                                                                {}\n",
      "        Flag_MesesDesdeVinculacion_Capped    int64     0.0         2                                                                {}\n",
      "\n",
      "[Correlación numéricas vs target] (top 20)\n",
      "NumeroCreditosGEstadoActivosPrevius                0.400\n",
      "creditos_activos_ratio                             0.396\n",
      "NumeroCreditosLEstadoActivosPrevius                0.216\n",
      "NumeroCreditosLPrevius                             0.201\n",
      "ratio_pagos_local_global                           0.182\n",
      "NumeroCreditosLEstadoPagadosPrevius                0.164\n",
      "Flag_NumeroCreditosGEstadoActivosPrevius_Capped    0.151\n",
      "Flag_PrimerUsoTemu                                 0.145\n",
      "Flag_TotalPagosEfectuadosLocalmentePrevius_NaN     0.137\n",
      "Flag_TotalPagosEfectuadosGlobalmentePrevius_NaN    0.137\n",
      "TotalPagosEfectuadosLocalmentePrevius              0.125\n",
      "Flag_DiasMaximosMoraCreditosGenerados_NaN          0.116\n",
      "UsabilidadCupo                                     0.114\n",
      "Flag_NumeroCreditosLEstadoActivosPrevius_Capped    0.101\n",
      "Flag_NumeroCreditosGPrevius_NaN                    0.101\n",
      "Flag_NumeroCreditosLEstadoPagadosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosLEstadoActivosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGEstadoPagadosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGEstadoActivosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGCanalVPrevius_NaN              0.101\n",
      "\n",
      "[Correlación numéricas vs target] (bottom 20)\n",
      "Flag_NumeroCreditosGPrevius_Capped                   -0.026\n",
      "Flag_NumeroCreditosGCanalFPrevius_Capped             -0.027\n",
      "Flag_TotalPagosEfectuadosGlobalmentePrevius_Capped   -0.028\n",
      "Flag_NumeroCreditosGEstadoPagadosPrevius_Capped      -0.029\n",
      "Flag_PrimerUsoAntesVinc                              -0.031\n",
      "MesesDesdePrimerUso                                  -0.046\n",
      "DiasDesdeUltimoUso                                   -0.048\n",
      "ScoreSinInfo                                         -0.056\n",
      "Edad                                                 -0.069\n",
      "CupoAprobado                                         -0.084\n",
      "NumeroCreditosGPrevius                               -0.087\n",
      "NumeroCreditosGCanalFPrevius                         -0.088\n",
      "TotalPagosEfectuadosGlobalmentePrevius               -0.098\n",
      "MesesDesdeVinculacion                                -0.101\n",
      "log_CupoAprobado                                     -0.102\n",
      "NumeroCreditosGEstadoPagadosPrevius                  -0.112\n",
      "Flag_UltimoUsoPosterior                                 NaN\n",
      "Flag_MesesDesdeVinculacion_NaN                          NaN\n",
      "Flag_MesesDesdePrimerUso_NaN                            NaN\n",
      "Flag_DiasDesdeUltimoUso_NaN                             NaN\n",
      "\n",
      "[Distribución Genero → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "Genero                             \n",
      "Masculino            0.753    0.247\n",
      "Desconocido          0.756    0.244\n",
      "Femenino             0.801    0.199\n",
      "\n",
      "[Distribución TipoMunicipioEntregaTC → proporción de pérdida por categoría]\n",
      "PerdidaCartera          no_perdida  perdida\n",
      "TipoMunicipioEntregaTC                     \n",
      "VIRTUAL                      0.722    0.278\n",
      "INTERMEDIO                   0.768    0.232\n",
      "PRINCIPAL                    0.796    0.204\n",
      "GRANDE                       0.816    0.184\n",
      "RURAL                        0.825    0.175\n",
      "PEQUEÑO                      0.837    0.163\n",
      "POBLADO                      0.839    0.161\n",
      "Desconocido                  0.940    0.060\n",
      "\n",
      "[Distribución CanalMunicipioEntregaTC → proporción de pérdida por categoría]\n",
      "PerdidaCartera           no_perdida  perdida\n",
      "CanalMunicipioEntregaTC                     \n",
      "Desconocido                   0.312    0.688\n",
      "Virtual                       0.722    0.278\n",
      "Fisico                        0.805    0.195\n",
      "\n",
      "[Distribución UsoAppWeb → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "UsoAppWeb                          \n",
      "App                  0.763    0.237\n",
      "Web                  0.775    0.225\n",
      "Desconocido          0.807    0.193\n",
      "\n",
      "[Distribución CategoriaPrincipalCredito → proporción de pérdida por categoría]\n",
      "PerdidaCartera               no_perdida  perdida\n",
      "CategoriaPrincipalCredito                       \n",
      "alimentos-y-bebidas               0.455    0.545\n",
      "pines-virtuales                   0.675    0.325\n",
      "bebes12255                        0.689    0.311\n",
      "ropa-y-accesorios                 0.695    0.305\n",
      "camaras-y-accesorios              0.709    0.291\n",
      "otras-categorias                  0.723    0.277\n",
      "juegos-y-juguetes                 0.732    0.268\n",
      "relojes-y-joyas                   0.735    0.265\n",
      "electronica,-audio-y-video        0.739    0.261\n",
      "accesorios-para-vehiculos         0.746    0.254\n",
      "celulares-y-telefonos             0.747    0.253\n",
      "cuidado-personal                  0.748    0.252\n",
      "arte,-papeleria-y-merceria        0.749    0.251\n",
      "electrodomesticos                 0.750    0.250\n",
      "computacion                       0.758    0.242\n",
      "consolas-y-videojuegos            0.763    0.237\n",
      "herramientas-y-construccion       0.764    0.236\n",
      "OtrosRare                         0.769    0.231\n",
      "deportes-y-fitness                0.785    0.215\n",
      "belleza-y-cuidado-personal        0.787    0.213\n",
      "animales-y-mascotas               0.787    0.213\n",
      "hogar-y-muebles                   0.789    0.211\n",
      "salud-y-equipamiento-medico       0.805    0.195\n",
      "Desconocido                       0.840    0.160\n",
      "\n",
      "[Distribución ScoreBucket → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "ScoreBucket                        \n",
      "bajo                 0.686    0.314\n",
      "medio                0.757    0.243\n",
      "sin_info             0.828    0.172\n",
      "alto                 0.847    0.153\n",
      "\n",
      "================= FIN EDA PREVIA (SIGUE MODELADO) =================\n",
      ">>> Sin columnas duplicadas en X.\n",
      ">>> Poda de columnas casi-constantes: ['Flag_UltimoUsoPosterior', 'Flag_MesesDesdeVinculacion_NaN', 'Flag_MesesDesdePrimerUso_NaN', 'Flag_DiasDesdeUltimoUso_NaN']\n",
      "\n",
      "=== Resumen columnas finales (previas al modelado) ===\n",
      "Numéricas: 54 | Categóricas: 7\n",
      "X shape: (146939, 61) | y rate (1): 0.226\n",
      "FechaEvento_dt rango: 2022-05-01 → 2023-10-31\n",
      "\n",
      ">>> Walk-forward CV (sin fuga):\n",
      "  - Split 1: train=(88163, 61), valid=(58776, 61), cutoff=2023-04-26\n",
      "[Logit+Cal (WF1)] ROC-AUC=0.558 | PR-AUC=0.284 | Brier=0.181\n",
      "[Logit+Cal (WF1)] Base rate y=1: 0.239 | mean(p1)=0.239 | mean(p0)=0.761\n",
      "[Logit+Cal (WF1)] best-F1=0.388 @ thr=0.191\n",
      "[Logit+Cal (WF1)] ConfMatrix @thr=0.191:\n",
      " [[ 2085 42651]\n",
      " [  403 13637]]\n",
      "[Logit+Cal (WF1)] Report @thr=0.191:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.838     0.047     0.088     44736\n",
      "           1      0.242     0.971     0.388     14040\n",
      "\n",
      "    accuracy                          0.267     58776\n",
      "   macro avg      0.540     0.509     0.238     58776\n",
      "weighted avg      0.696     0.267     0.160     58776\n",
      "\n",
      "[HGB+Cal (WF1)] ROC-AUC=0.849 | PR-AUC=0.648 | Brier=0.124\n",
      "[HGB+Cal (WF1)] Base rate y=1: 0.239 | mean(p1)=0.239 | mean(p0)=0.761\n",
      "[HGB+Cal (WF1)] best-F1=0.619 @ thr=0.291\n",
      "[HGB+Cal (WF1)] ConfMatrix @thr=0.291:\n",
      " [[36894  7842]\n",
      " [ 4230  9810]]\n",
      "[HGB+Cal (WF1)] Report @thr=0.291:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.897     0.825     0.859     44736\n",
      "           1      0.556     0.699     0.619     14040\n",
      "\n",
      "    accuracy                          0.795     58776\n",
      "   macro avg      0.726     0.762     0.739     58776\n",
      "weighted avg      0.816     0.795     0.802     58776\n",
      "\n",
      "  - Split 2: train=(102857, 61), valid=(44082, 61), cutoff=2023-06-11\n",
      "[Logit+Cal (WF2)] ROC-AUC=0.569 | PR-AUC=0.285 | Brier=0.176\n",
      "[Logit+Cal (WF2)] Base rate y=1: 0.230 | mean(p1)=0.230 | mean(p0)=0.770\n",
      "[Logit+Cal (WF2)] best-F1=0.376 @ thr=0.175\n",
      "[Logit+Cal (WF2)] ConfMatrix @thr=0.175:\n",
      " [[ 1564 32387]\n",
      " [  297  9834]]\n",
      "[Logit+Cal (WF2)] Report @thr=0.175:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.840     0.046     0.087     33951\n",
      "           1      0.233     0.971     0.376     10131\n",
      "\n",
      "    accuracy                          0.259     44082\n",
      "   macro avg      0.537     0.508     0.232     44082\n",
      "weighted avg      0.701     0.259     0.154     44082\n",
      "\n",
      "[HGB+Cal (WF2)] ROC-AUC=0.844 | PR-AUC=0.615 | Brier=0.124\n",
      "[HGB+Cal (WF2)] Base rate y=1: 0.230 | mean(p1)=0.230 | mean(p0)=0.770\n",
      "[HGB+Cal (WF2)] best-F1=0.604 @ thr=0.294\n",
      "[HGB+Cal (WF2)] ConfMatrix @thr=0.294:\n",
      " [[27730  6221]\n",
      " [ 3062  7069]]\n",
      "[HGB+Cal (WF2)] Report @thr=0.294:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.901     0.817     0.857     33951\n",
      "           1      0.532     0.698     0.604     10131\n",
      "\n",
      "    accuracy                          0.789     44082\n",
      "   macro avg      0.716     0.757     0.730     44082\n",
      "weighted avg      0.816     0.789     0.798     44082\n",
      "\n",
      "  - Split 3: train=(117551, 61), valid=(29388, 61), cutoff=2023-07-29\n",
      "[Logit+Cal (WF3)] ROC-AUC=0.589 | PR-AUC=0.275 | Brier=0.163\n",
      "[Logit+Cal (WF3)] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[Logit+Cal (WF3)] best-F1=0.358 @ thr=0.227\n",
      "[Logit+Cal (WF3)] ConfMatrix @thr=0.227:\n",
      " [[13086 10205]\n",
      " [ 2545  3552]]\n",
      "[Logit+Cal (WF3)] Report @thr=0.227:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.837     0.562     0.672     23291\n",
      "           1      0.258     0.583     0.358      6097\n",
      "\n",
      "    accuracy                          0.566     29388\n",
      "   macro avg      0.548     0.572     0.515     29388\n",
      "weighted avg      0.717     0.566     0.607     29388\n",
      "\n",
      "[HGB+Cal (WF3)] ROC-AUC=0.839 | PR-AUC=0.557 | Brier=0.120\n",
      "[HGB+Cal (WF3)] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[HGB+Cal (WF3)] best-F1=0.575 @ thr=0.265\n",
      "[HGB+Cal (WF3)] ConfMatrix @thr=0.265:\n",
      " [[18643  4648]\n",
      " [ 1786  4311]]\n",
      "[HGB+Cal (WF3)] Report @thr=0.265:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.800     0.853     23291\n",
      "           1      0.481     0.707     0.573      6097\n",
      "\n",
      "    accuracy                          0.781     29388\n",
      "   macro avg      0.697     0.754     0.713     29388\n",
      "weighted avg      0.823     0.781     0.795     29388\n",
      "\n",
      "\n",
      "Logit — Walk-forward CV:\n",
      "                         cutoff   roc_auc    pr_auc     brier       thr\n",
      "0 2023-04-26 00:30:52.808999936  0.558101  0.283581  0.180803  0.190750\n",
      "1 2023-06-11 16:14:11.783000064  0.569474  0.284715  0.175720  0.175010\n",
      "2 2023-07-29 19:52:43.941999872  0.588571  0.275172  0.162625  0.227073\n",
      "Logit — medias: ROC-AUC=0.572 | PR-AUC=0.281 | Brier=0.173\n",
      "\n",
      "HGB — Walk-forward CV:\n",
      "                         cutoff   roc_auc    pr_auc     brier       thr\n",
      "0 2023-04-26 00:30:52.808999936  0.848629  0.647578  0.123772  0.290625\n",
      "1 2023-06-11 16:14:11.783000064  0.843766  0.614984  0.124089  0.294118\n",
      "2 2023-07-29 19:52:43.941999872  0.838577  0.557450  0.120149  0.264672\n",
      "HGB — medias:   ROC-AUC=0.844 | PR-AUC=0.607 | Brier=0.123\n",
      "\n",
      ">>> Modelo elegido por PR-AUC medio: HGB\n",
      "\n",
      ">>> Holdout temporal: train=(117551, 61), holdout=(29388, 61), corte=2023-07-29\n",
      ">>> Checks anti-fuga:\n",
      "OK sin fuga\n",
      "\n",
      "[HOLDOUT-HGB] ROC-AUC=0.839 | PR-AUC=0.557 | Brier=0.120\n",
      "[HOLDOUT-HGB] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[HOLDOUT-HGB] best-F1=0.575 @ thr=0.265\n",
      "[HOLDOUT-HGB] ConfMatrix @thr=0.265:\n",
      " [[18643  4648]\n",
      " [ 1786  4311]]\n",
      "[HOLDOUT-HGB] Report @thr=0.265:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.800     0.853     23291\n",
      "           1      0.481     0.707     0.573      6097\n",
      "\n",
      "    accuracy                          0.781     29388\n",
      "   macro avg      0.697     0.754     0.713     29388\n",
      "weighted avg      0.823     0.781     0.795     29388\n",
      "\n",
      "\n",
      "[HOLDOUT-HGB] Puntos de operación sugeridos:\n",
      " - maxF1     : thr=0.265 | precision=0.504 | recall=0.669 | F1=0.575\n",
      " - prec>=0.6 : thr=0.448 | precision=0.666 | recall=0.327 | F1=0.439\n",
      " - rec>=0.7  : thr=0.250 | precision=0.481 | recall=0.707 | F1=0.573\n",
      "\n",
      "[Barrido de umbrales clase 1]\n",
      " thr  prec1  rec1   TP   FP   FN    TN\n",
      " 0.2  0.426 0.804 4905 6604 1192 16687\n",
      " 0.3  0.513 0.654 3988 3780 2109 19511\n",
      " 0.4  0.546 0.590 3600 2994 2497 20297\n",
      " 0.5  0.693 0.300 1831  811 4266 22480\n",
      "\n",
      "[Objetivo] PRECISIÓN≥0.80 en morosos @thr=0.763\n",
      "  TP=266 FP=78 FN=5831 TN=23213\n",
      "  precision1=0.773 recall1=0.044 (morosos)\n",
      "  %alertados=0.012 %morosos_detectados=0.009\n",
      "\n",
      ">>> Modelo calibrado guardado en artifacts_modelo/modelo_calibrado.joblib\n",
      "\n",
      "[HOLDOUT-HGB] Calibración por deciles (p_mean vs y_rate):\n",
      "           index   p_mean   y_rate    n\n",
      "(-0.001, 0.0157] 0.010896 0.010896 4497\n",
      "(0.0157, 0.0255] 0.025153 0.025153 1471\n",
      "(0.0255, 0.0436] 0.039778 0.039778 3067\n",
      "(0.0436, 0.0693] 0.064372 0.064372 2905\n",
      " (0.0693, 0.132] 0.103796 0.103796 2977\n",
      "  (0.132, 0.197] 0.164754 0.164754 2962\n",
      "  (0.197, 0.265] 0.241006 0.241006 3419\n",
      "  (0.265, 0.448] 0.409572 0.409572 5098\n",
      "  (0.448, 0.452] 0.452174 0.452174  115\n",
      "  (0.452, 0.846] 0.674661 0.674661 2877\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODELO DE RIESGO — VALIDACIÓN TEMPORAL ESTRICTA (SIN FUGA)\n",
    "# ============================================================\n",
    "# Requiere: pandas, numpy, scikit-learn, joblib\n",
    "# Supone que 'clientes' (crudo) está disponible en memoria.\n",
    "#   - columnas de fecha: FechaEvento, FechaVinculacionCliente, FechaUltimoUso, FechaPrimerUso\n",
    "#   - target: PerdidaCartera (0/1)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss,\n",
    "    classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) CONFIG\n",
    "# -----------------------------\n",
    "TARGET = \"PerdidaCartera\"\n",
    "RANDOM_STATE = 42\n",
    "ARTIF_DIR = Path(\"./artifacts_modelo\"); ARTIF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# ============================================================\n",
    "# 1) INGESTA (usa tu carga real). Aseguramos target y forma.\n",
    "# ============================================================\n",
    "# EJEMPLO (descomenta si lo necesitas):\n",
    "# clientes = pd.read_parquet(\"data/clientes.parquet\")\n",
    "\n",
    "assert TARGET in clientes.columns, f\"No encuentro columna target '{TARGET}' en 'clientes'\"\n",
    "print(\">>> SHAPE crudo:\", clientes.shape)\n",
    "print(\">>> Columnas (primeras 20):\", list(clientes.columns)[:20])\n",
    "\n",
    "# ============================================================\n",
    "# 2) FEATURE ENGINEERING — SIN FUGA\n",
    "# ============================================================\n",
    "def parse_and_features(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # --- Fechas\n",
    "    df['FechaEvento_dt'] = (\n",
    "        pd.to_datetime(df['FechaEvento'], errors='coerce', utc=True)\n",
    "          .dt.tz_convert(None)\n",
    "    )\n",
    "    df['FechaVinculacionCliente_dt'] = pd.to_datetime(\n",
    "        df['FechaVinculacionCliente'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaUltimoUso_dt'] = pd.to_datetime(\n",
    "        df['FechaUltimoUso'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaPrimerUso_dt'] = pd.to_datetime(\n",
    "        df['FechaPrimerUso'], errors='coerce',\n",
    "        origin='1904-01-01', unit='D'\n",
    "    )\n",
    "\n",
    "    # Corrección conservadora PrimerUso\n",
    "    df['Flag_PrimerUsoAntesVinc'] = (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt']).astype(int)\n",
    "    mask_bad = df['FechaPrimerUso_dt'].isna() | (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt'])\n",
    "    df.loc[mask_bad,  'FechaPrimerUso_corr'] = df.loc[mask_bad,  'FechaVinculacionCliente_dt']\n",
    "    df.loc[~mask_bad, 'FechaPrimerUso_corr'] = df.loc[~mask_bad, 'FechaPrimerUso_dt']\n",
    "\n",
    "    # Diferencias seguras\n",
    "    def safe_months(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d / 30.0\n",
    "\n",
    "    def safe_days(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d\n",
    "\n",
    "    df['MesesDesdeVinculacion'] = safe_months(df['FechaEvento_dt'], df['FechaVinculacionCliente_dt'])\n",
    "    df['MesesDesdePrimerUso']   = safe_months(df['FechaEvento_dt'], df['FechaPrimerUso_corr'])\n",
    "    df['DiasDesdeUltimoUso']    = safe_days(df['FechaEvento_dt'],  df['FechaUltimoUso_dt'])\n",
    "\n",
    "    # --- Usabilidad\n",
    "    df['UsabilidadCupo'] = pd.to_numeric(df['UsabilidadCupo'], errors='coerce')\n",
    "    df['Flag_Usab_NaN']    = df['UsabilidadCupo'].isna().astype(int)\n",
    "    df['Flag_Usab_Outlier']= ((df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2)).astype(int)\n",
    "    df.loc[(df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2), 'UsabilidadCupo'] = np.nan\n",
    "    df['UsabilidadCupo']   = df['UsabilidadCupo'].fillna(df['UsabilidadCupo'].median())\n",
    "\n",
    "    # --- Flags de fechas\n",
    "    df['Flag_UltimoUsoPosterior'] = (df['FechaUltimoUso_dt'] > df['FechaEvento_dt']).fillna(False).astype(int)\n",
    "\n",
    "    # --- Numéricas con nulos —> flags + imputación conservadora\n",
    "    num_cols_candidates = [\n",
    "        'DiasMaximosMoraCreditosGenerados',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','CupoAprobado','ScoreCrediticio','Edad',\n",
    "        'MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso'\n",
    "    ]\n",
    "    for c in num_cols_candidates:\n",
    "        if c in df.columns:\n",
    "            df[f'Flag_{c}_NaN'] = df[c].isna().astype(int)\n",
    "            if c.startswith('NumeroCreditos') or c.startswith('TotalPagos'):\n",
    "                df[c] = df[c].fillna(0)\n",
    "            elif c in ['DiasMaximosMoraCreditosGenerados','Edad','NumeroIntentosFallidos']:\n",
    "                df[c] = df[c].fillna(0)\n",
    "\n",
    "    # --- Score & Cupo\n",
    "    df['ScoreSinInfo'] = (df['ScoreCrediticio'] == 0).astype(int)\n",
    "    if df['ScoreCrediticio'].isna().any():\n",
    "        med_pos = df.loc[df['ScoreCrediticio']>0, 'ScoreCrediticio'].median()\n",
    "        df['ScoreCrediticio'] = df['ScoreCrediticio'].fillna(med_pos)\n",
    "\n",
    "    df['log_CupoAprobado'] = np.log1p(df['CupoAprobado'])\n",
    "    df['log_CupoAprobado'] = df['log_CupoAprobado'].fillna(df['log_CupoAprobado'].median())\n",
    "\n",
    "    # --- Categóricas limpias\n",
    "    for c in ['CategoriaPrincipalCredito','UsoAppWeb','Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna('Desconocido')\n",
    "    df['Genero'] = df['Genero'].replace({27:'Desconocido'})\n",
    "    df['TipoMunicipioEntregaTC'] = df['TipoMunicipioEntregaTC'].replace({'PEQUEÃ‘O':'PEQUEÑO'}).fillna('Desconocido')\n",
    "\n",
    "    # --- Rango de Edad\n",
    "    df['Flag_Edad_Out'] = (~df['Edad'].between(18, 100, inclusive='both')).fillna(False).astype(int)\n",
    "    df.loc[df['Flag_Edad_Out']==1, 'Edad'] = np.nan\n",
    "    df['Edad'] = df['Edad'].fillna(df['Edad'].median())\n",
    "\n",
    "    # --- Features derivadas clave\n",
    "    if 'Flag_PrimerUsoTemu' not in df.columns and 'NumeroCreditosGPrevius' in df.columns:\n",
    "        df['Flag_PrimerUsoTemu'] = (df['NumeroCreditosGPrevius'] == 0).astype(int)\n",
    "\n",
    "    df['ratio_pagos_local_global'] = (\n",
    "        df['TotalPagosEfectuadosLocalmentePrevius'].fillna(0) /\n",
    "        (df['TotalPagosEfectuadosGlobalmentePrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    df['creditos_activos_ratio'] = (\n",
    "        df['NumeroCreditosGEstadoActivosPrevius'].fillna(0) /\n",
    "        (df['NumeroCreditosGPrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    for c in ['ratio_pagos_local_global','creditos_activos_ratio']:\n",
    "        df[c] = df[c].replace([np.inf,-np.inf], np.nan).fillna(0).clip(0,1)\n",
    "\n",
    "    df['Flag_CanalVirtual'] = (\n",
    "        (df['CanalMunicipioEntregaTC'].astype(str).str.lower()=='virtual') |\n",
    "        (df['TipoMunicipioEntregaTC'].astype(str).str.upper()=='VIRTUAL')\n",
    "    ).astype(int)\n",
    "\n",
    "    # --- Score negativo -> 0, más bucket\n",
    "    df['Flag_Score_Negativo'] = (df['ScoreCrediticio'] < 0).astype(int)\n",
    "    df.loc[df['ScoreCrediticio'] < 0, 'ScoreCrediticio'] = 0\n",
    "\n",
    "    df['ScoreBucket'] = 'sin_info'\n",
    "    mask_pos = df['ScoreCrediticio'] > 0\n",
    "    if mask_pos.sum() > 0:\n",
    "        b1, b2 = df.loc[mask_pos, 'ScoreCrediticio'].quantile([0.33, 0.66]).values\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] <= b1), 'ScoreBucket'] = 'bajo'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b1) & (df['ScoreCrediticio'] <= b2), 'ScoreBucket'] = 'medio'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b2), 'ScoreBucket'] = 'alto'\n",
    "    df['ScoreBucket'] = pd.Categorical(df['ScoreBucket'], categories=['sin_info','bajo','medio','alto'], ordered=True)\n",
    "\n",
    "    # --- Winsorización p99 + flags (colas largas)\n",
    "    def cap_with_flag(s, upper):\n",
    "        flag = (s > upper).astype(int)\n",
    "        return np.where(s > upper, upper, s), flag\n",
    "\n",
    "    cap_cols = [\n",
    "        'DiasDesdeUltimoUso','MesesDesdeVinculacion',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius'\n",
    "    ]\n",
    "    for c in cap_cols:\n",
    "        if c in df.columns:\n",
    "            p99 = df[c].quantile(0.99)\n",
    "            capped, flag = cap_with_flag(df[c].fillna(0), p99)\n",
    "            df[c] = capped\n",
    "            df[f'Flag_{c}_Capped'] = flag\n",
    "\n",
    "    # Agrupar categorías raras de CategoriaPrincipalCredito (<0.1%)\n",
    "    if 'CategoriaPrincipalCredito' in df.columns:\n",
    "        vc = df['CategoriaPrincipalCredito'].astype(str).value_counts(dropna=False)\n",
    "        cutoff = df.shape[0] * 0.001\n",
    "        rare_levels = vc[vc < cutoff].index\n",
    "        df['CategoriaPrincipalCredito'] = df['CategoriaPrincipalCredito'].astype(str)\n",
    "        df.loc[df['CategoriaPrincipalCredito'].isin(rare_levels), 'CategoriaPrincipalCredito'] = 'OtrosRare'\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_feature_lists(df: pd.DataFrame):\n",
    "    drop_from_features = [\n",
    "        'IdentificadorCliente','FechaEvento','FechaVinculacionCliente','FechaPrimerUso','FechaUltimoUso',\n",
    "        'FechaEvento_dt','FechaVinculacionCliente_dt','FechaPrimerUso_dt','FechaUltimoUso_dt','FechaPrimerUso_corr',\n",
    "        'CodigoAlmacenEntregaTC','CodigoAlmacenEntregaTC_str','AlmacenTop20',\n",
    "        'CodigoMunicipioEntregaTC','MunicipioCat','MunicipioTop20','MesCompra',\n",
    "        'DiasMora'\n",
    "    ]\n",
    "    num_base = [\n",
    "        'UsabilidadCupo','MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','ScoreCrediticio','ScoreSinInfo','CupoAprobado','log_CupoAprobado','Edad',\n",
    "        'Flag_Usab_NaN','Flag_Usab_Outlier','Flag_PrimerUsoAntesVinc','Flag_UltimoUsoPosterior','Flag_Edad_Out',\n",
    "        'ratio_pagos_local_global','creditos_activos_ratio','Flag_Score_Negativo'\n",
    "    ]\n",
    "    num_dyn = [c for c in df.columns if c.startswith('Flag_') and (c.endswith('_NaN') or c.endswith('_Capped'))]\n",
    "    num_final = [c for c in (num_base + num_dyn) if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    cat_final = [\n",
    "        'Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC','UsoAppWeb','CategoriaPrincipalCredito',\n",
    "        'Flag_PrimerUsoTemu','ScoreBucket'\n",
    "    ]\n",
    "    cat_final = [c for c in cat_final if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    # Evitar solape entre num y cat + forzar unicidad y orden estable\n",
    "    overlap = set(num_final) & set(cat_final)\n",
    "    if overlap:\n",
    "        print(f\">>> Aviso: {len(overlap)} columnas estaban en num y cat. Se quitan de num: {sorted(overlap)}\")\n",
    "        num_final = [c for c in num_final if c not in overlap]\n",
    "\n",
    "    num_final = list(dict.fromkeys(num_final))\n",
    "    cat_final = list(dict.fromkeys(cat_final))\n",
    "    return num_final, cat_final\n",
    "\n",
    "\n",
    "def prune_low_variance(X: pd.DataFrame):\n",
    "    low_var = [c for c in X.columns if X[c].nunique(dropna=False) <= 1]\n",
    "    if low_var:\n",
    "        print(\">>> Poda de columnas casi-constantes:\", low_var)\n",
    "        return X.drop(columns=low_var, errors='ignore'), low_var\n",
    "    else:\n",
    "        print(\">>> Poda de columnas casi-constantes: ninguna\")\n",
    "        return X, []\n",
    "\n",
    "\n",
    "def build_pipelines(cat_cols, num_cols):\n",
    "    pre_logit = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "            ]), cat_cols),\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='median'))\n",
    "            ]), num_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    logit = Pipeline(steps=[\n",
    "        ('pre', pre_logit),\n",
    "        ('clf', LogisticRegression(\n",
    "            solver='saga', penalty='l2', class_weight='balanced',\n",
    "            max_iter=800, n_jobs=-1, random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pre_hgb = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "            ('num', 'passthrough', num_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    hgb = Pipeline(steps=[\n",
    "        ('pre', pre_hgb),\n",
    "        ('clf', HistGradientBoostingClassifier(\n",
    "            learning_rate=0.07, max_leaf_nodes=31, l2_regularization=1.0,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    return logit, hgb\n",
    "\n",
    "\n",
    "def evaluate_proba(y_true, y_proba, name=\"model\"):\n",
    "    # Métricas de probas + resumen de ambos lados\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    ap  = average_precision_score(y_true, y_proba)\n",
    "    br  = brier_score_loss(y_true, y_proba)\n",
    "    print(f\"[{name}] ROC-AUC={auc:.3f} | PR-AUC={ap:.3f} | Brier={br:.3f}\")\n",
    "    print(f\"[{name}] Base rate y=1: {y_true.mean():.3f} | mean(p1)={np.mean(y_proba):.3f} | mean(p0)={np.mean(1-y_proba):.3f}\")\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    j  = np.argmax(f1)\n",
    "    best_thr = thr[j-1] if j>0 and j-1 < len(thr) else 0.5\n",
    "    y_hat = (y_proba >= best_thr).astype(int)\n",
    "    print(f\"[{name}] best-F1={f1[j]:.3f} @ thr={best_thr:.3f}\")\n",
    "    print(f\"[{name}] ConfMatrix @thr={best_thr:.3f}:\\n\", confusion_matrix(y_true, y_hat))\n",
    "    print(f\"[{name}] Report @thr={best_thr:.3f}:\\n\", classification_report(y_true, y_hat, digits=3))\n",
    "    return dict(roc_auc=auc, pr_auc=ap, brier=br, thr=best_thr)\n",
    "\n",
    "\n",
    "def operating_points(y_true, y_proba, name=\"model\"):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    pts = {}\n",
    "    # máx F1\n",
    "    j = np.argmax(f1); pts['maxF1'] = (thr[j-1] if j>0 else 0.5, p[j], r[j], f1[j])\n",
    "    # precisión >= 0.6\n",
    "    idx = np.where(p>=0.6)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(r[idx])]\n",
    "        pts['prec>=0.6'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "    # recall >= 0.7\n",
    "    idx = np.where(r>=0.7)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(p[idx])]\n",
    "        pts['rec>=0.7'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "\n",
    "    print(f\"\\n[{name}] Puntos de operación sugeridos:\")\n",
    "    for kk,(t,pp,rr,ff) in pts.items():\n",
    "        print(f\" - {kk:10s}: thr={t:.3f} | precision={pp:.3f} | recall={rr:.3f} | F1={ff:.3f}\")\n",
    "    return pts\n",
    "\n",
    "\n",
    "def walk_forward_cv(df, X, y, cat_cols, num_cols, cut_fracs=(0.6,0.7,0.8)):\n",
    "    \"\"\"Valida SIN FUGA con 3 cortes temporales (ajustable).\"\"\"\n",
    "    cutoffs = df['FechaEvento_dt'].quantile(list(cut_fracs)).values\n",
    "    rows_l, rows_h = [], []\n",
    "    logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "\n",
    "    print(\"\\n>>> Walk-forward CV (sin fuga):\")\n",
    "    for i, c in enumerate(cutoffs, 1):\n",
    "        tr_idx = df['FechaEvento_dt'] <= c\n",
    "        va_idx = df['FechaEvento_dt'] >  c\n",
    "        X_tr, X_va = X.loc[tr_idx], X.loc[va_idx]\n",
    "        y_tr, y_va = y.loc[tr_idx], y.loc[va_idx]\n",
    "        print(f\"  - Split {i}: train={X_tr.shape}, valid={X_va.shape}, cutoff={pd.Timestamp(c).date()}\")\n",
    "\n",
    "        # Logit + calibración\n",
    "        logit.fit(X_tr, y_tr)\n",
    "        cal_logit = CalibratedClassifierCV(logit, method='sigmoid', cv='prefit')\n",
    "        cal_logit.fit(X_va, y_va)\n",
    "        proba_l = cal_logit.predict_proba(X_va)[:,1]\n",
    "        m_l = evaluate_proba(y_va, proba_l, name=f\"Logit+Cal (WF{i})\")\n",
    "        rows_l.append({\"cutoff\": c, **m_l})\n",
    "\n",
    "        # HGB + sample_weight + calibración\n",
    "        sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "        hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "        cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "        cal_hgb.fit(X_va, y_va)\n",
    "        proba_h = cal_hgb.predict_proba(X_va)[:,1]\n",
    "        m_h = evaluate_proba(y_va, proba_h, name=f\"HGB+Cal (WF{i})\")\n",
    "        rows_h.append({\"cutoff\": c, **m_h})\n",
    "\n",
    "    return pd.DataFrame(rows_l), pd.DataFrame(rows_h)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CONSTRUIR DATASET LIMPIO + LISTAS DE FEATURES + EDA\n",
    "# ============================================================\n",
    "print(\"\\n>>> Construyendo features (sin fuga) ...\")\n",
    "clientes = parse_and_features(clientes)\n",
    "num_final, cat_final = build_feature_lists(clientes)\n",
    "\n",
    "X = clientes[num_final + cat_final].copy()\n",
    "y = clientes[TARGET].astype(int).copy()\n",
    "\n",
    "# 3A) EDA previa (resumen, correlaciones, crosstabs)\n",
    "print(\"\\n===================== EDA PREVIA (SIN FUGA) =====================\")\n",
    "print(f\"Shape de X: {X.shape} | y rate (1)= {y.mean():.3f}\")\n",
    "print(\"Rango de fechas (FechaEvento_dt):\",\n",
    "      str(clientes['FechaEvento_dt'].min().date()), \"→\", str(clientes['FechaEvento_dt'].max().date()))\n",
    "\n",
    "vc = y.value_counts().rename({0:'no_perdida', 1:'perdida'})\n",
    "print(\"\\n[Balance de clases]\")\n",
    "print(pd.concat([vc, (vc/vc.sum()).round(3).rename('pct')], axis=1).to_string())\n",
    "\n",
    "summary_rows = []\n",
    "for c in X.columns:\n",
    "    s = X[c]\n",
    "    dtype = s.dtype\n",
    "    pct_null = s.isnull().mean()*100\n",
    "    nuni = s.nunique(dropna=False)\n",
    "    # FIX: usar is_numeric_dtype para que no falle con CategoricalDtype\n",
    "    top5 = s.value_counts(dropna=False).head(5).to_dict() if (not is_numeric_dtype(s)) else {}\n",
    "    summary_rows.append({\n",
    "        'columna': c, 'dtype': str(dtype), '%nulos': round(pct_null,1),\n",
    "        'n_unicos': int(nuni), 'top5_valores': top5\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(['dtype','columna'])\n",
    "print(\"\\n[Resumen por columna] (primeras 30 filas)\")\n",
    "print(summary_df.head(30).to_string(index=False))\n",
    "summary_df.to_csv(ARTIF_DIR/\"eda_resumen_columnas.csv\", index=False)\n",
    "\n",
    "num_cols_for_corr = [c for c in X.columns if is_numeric_dtype(X[c]) and c != TARGET]\n",
    "if len(num_cols_for_corr) > 0:\n",
    "    corrs = X[num_cols_for_corr].corrwith(y).sort_values(ascending=False)\n",
    "    print(\"\\n[Correlación numéricas vs target] (top 20)\")\n",
    "    print(corrs.head(20).round(3).to_string())\n",
    "    print(\"\\n[Correlación numéricas vs target] (bottom 20)\")\n",
    "    print(corrs.tail(20).round(3).to_string())\n",
    "\n",
    "cat_cols_for_xtab = [c for c in X.columns if not is_numeric_dtype(X[c])]\n",
    "for c in cat_cols_for_xtab:\n",
    "    # sólo crosstab para cardinalidad moderada\n",
    "    if X[c].nunique(dropna=False) <= 25:\n",
    "        tab = pd.crosstab(X[c], y, normalize='index').rename(columns={0:'no_perdida',1:'perdida'}).round(3)\n",
    "        print(f\"\\n[Distribución {c} → proporción de pérdida por categoría]\")\n",
    "        print(tab.sort_values('perdida', ascending=False).to_string())\n",
    "\n",
    "print(\"\\n================= FIN EDA PREVIA (SIGUE MODELADO) =================\")\n",
    "\n",
    "# 3B) Limpiezas extra útiles antes de modelar\n",
    "# --- ELIMINAR COLUMNAS DUPLICADAS EN X ---\n",
    "dups_mask = X.columns.duplicated(keep='first')\n",
    "if dups_mask.any():\n",
    "    dups = pd.Series(X.columns)[dups_mask].tolist()\n",
    "    print(f\">>> Columnas duplicadas detectadas y removidas ({len(dups)}): {dups}\")\n",
    "    X = X.loc[:, ~X.columns.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\">>> Sin columnas duplicadas en X.\")\n",
    "\n",
    "# --- PODA BAJA VARIANZA ---\n",
    "X, dropped_lowvar = prune_low_variance(X)\n",
    "\n",
    "print(\"\\n=== Resumen columnas finales (previas al modelado) ===\")\n",
    "print(f\"Numéricas: {len([c for c in X.columns if c in num_final])} | Categóricas: {len([c for c in X.columns if c in cat_final])}\")\n",
    "print(\"X shape:\", X.shape, \"| y rate (1):\", y.mean().round(3))\n",
    "print(\"FechaEvento_dt rango:\", str(clientes['FechaEvento_dt'].min().date()), \"→\", str(clientes['FechaEvento_dt'].max().date()))\n",
    "\n",
    "# ============================================================\n",
    "# 4) WALK-FORWARD CV — SIN MIRAR EL FUTURO\n",
    "# ============================================================\n",
    "cat_cols = [c for c in cat_final if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "logit_cv, hgb_cv = walk_forward_cv(clientes, X, y, cat_cols, num_cols)\n",
    "\n",
    "print(\"\\nLogit — Walk-forward CV:\")\n",
    "print(logit_cv)\n",
    "print(f\"Logit — medias: ROC-AUC={logit_cv.roc_auc.mean():.3f} | PR-AUC={logit_cv.pr_auc.mean():.3f} | Brier={logit_cv.brier.mean():.3f}\")\n",
    "\n",
    "print(\"\\nHGB — Walk-forward CV:\")\n",
    "print(hgb_cv)\n",
    "print(f\"HGB — medias:   ROC-AUC={hgb_cv.roc_auc.mean():.3f} | PR-AUC={hgb_cv.pr_auc.mean():.3f} | Brier={hgb_cv.brier.mean():.3f}\")\n",
    "\n",
    "chosen = \"HGB\" if hgb_cv.pr_auc.mean() >= logit_cv.pr_auc.mean() else \"Logit\"\n",
    "print(f\"\\n>>> Modelo elegido por PR-AUC medio: {chosen}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) HOLDOUT FINAL (FUTURO) — EVALUAR Y BUSCAR PRECISIÓN >=0.80\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "# Split temporal\n",
    "cutoff = clientes['FechaEvento_dt'].quantile(0.8)\n",
    "train_idx = clientes['FechaEvento_dt'] <= cutoff\n",
    "hold_idx  = clientes['FechaEvento_dt'] >  cutoff\n",
    "X_tr, X_ho = X.loc[train_idx], X.loc[hold_idx]\n",
    "y_tr, y_ho = y.loc[train_idx], y.loc[hold_idx]\n",
    "\n",
    "print(f\"\\n>>> Holdout temporal: train={X_tr.shape}, holdout={X_ho.shape}, corte={pd.Timestamp(cutoff).date()}\")\n",
    "print(\">>> Checks anti-fuga:\")\n",
    "assert set(X_tr.index).isdisjoint(set(X_ho.index)), \"¡Solapamiento entre train y holdout!\"\n",
    "assert clientes.loc[X_tr.index,'FechaEvento_dt'].max() <= cutoff\n",
    "assert clientes.loc[X_ho.index,'FechaEvento_dt'].min() > cutoff\n",
    "print(\"OK sin fuga\\n\")\n",
    "\n",
    "# Entrena modelo elegido\n",
    "logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "cal_hgb.fit(X_ho, y_ho)\n",
    "proba_hgb = cal_hgb.predict_proba(X_ho)[:,1]\n",
    "\n",
    "# Métricas generales en holdout\n",
    "_ = evaluate_proba(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "operating_points(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# -------- función para barrer umbrales\n",
    "def sweep_thresholds(y_true, y_proba, thresholds=(0.2,0.3,0.4,0.5)):\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yhat = (y_proba >= t).astype(int)\n",
    "        TN, FP, FN, TP = confusion_matrix(y_true, yhat).ravel()\n",
    "        prec1 = TP/(TP+FP) if TP+FP>0 else 0\n",
    "        rec1  = TP/(TP+FN) if TP+FN>0 else 0\n",
    "        rows.append({\"thr\":t,\"prec1\":round(prec1,3),\"rec1\":round(rec1,3),\"TP\":TP,\"FP\":FP,\"FN\":FN,\"TN\":TN})\n",
    "    print(\"\\n[Barrido de umbrales clase 1]\")\n",
    "    print(pd.DataFrame(rows).to_string(index=False))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tab_thr = sweep_thresholds(y_ho, proba_hgb)\n",
    "\n",
    "# -------- encontrar umbral que cumpla PRECISIÓN >= 0.80 para clase 1\n",
    "p, r, thr = precision_recall_curve(y_ho, proba_hgb)\n",
    "idx = np.where(p >= 0.80)[0]\n",
    "if len(idx) == 0:\n",
    "    print(\"\\n>>> No existe punto con precisión ≥0.80. Necesitas nuevas variables o aceptar menor recall.\")\n",
    "else:\n",
    "    k = idx[np.argmax(r[idx])]\n",
    "    thr_p80 = thr[k-1] if k>0 else 0.5\n",
    "    yhat = (proba_hgb >= thr_p80).astype(int)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_ho, yhat).ravel()\n",
    "    prec1 = TP/(TP+FP) if TP+FP>0 else 0\n",
    "    rec1  = TP/(TP+FN) if TP+FN>0 else 0\n",
    "    print(f\"\\n[Objetivo] PRECISIÓN≥0.80 en morosos @thr={thr_p80:.3f}\")\n",
    "    print(f\"  TP={TP} FP={FP} FN={FN} TN={TN}\")\n",
    "    print(f\"  precision1={prec1:.3f} recall1={rec1:.3f} (morosos)\")\n",
    "    print(f\"  %alertados={(TP+FP)/len(y_ho):.3f} %morosos_detectados={TP/len(y_ho):.3f}\")\n",
    "\n",
    "# -------- guardar modelo calibrado\n",
    "bundle = {\n",
    "    \"model_calibrado\": cal_hgb,\n",
    "    \"num_final\": num_final,\n",
    "    \"cat_final\": cat_final,\n",
    "    \"columns_after_prune\": list(X.columns),\n",
    "    \"cutoff\": cutoff\n",
    "}\n",
    "joblib.dump(bundle, ARTIF_DIR/\"modelo_calibrado.joblib\")\n",
    "print(f\"\\n>>> Modelo calibrado guardado en {ARTIF_DIR/'modelo_calibrado.joblib'}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) CALIBRACIÓN POR DECILES EN HOLDOUT\n",
    "# ============================================================\n",
    "def decile_calibration(y_true, y_proba, name=\"holdout\"):\n",
    "    bins = pd.qcut(y_proba, q=10, duplicates='drop')\n",
    "    tab = pd.DataFrame({\"p\":y_proba, \"y\":y_true}).groupby(bins, observed=True).agg(\n",
    "        p_mean=('p','mean'),\n",
    "        y_rate=('y','mean'),\n",
    "        n=('p','size')\n",
    "    ).reset_index().rename(columns={\"p\":\"bin\"})\n",
    "    print(f\"\\n[{name}] Calibración por deciles (p_mean vs y_rate):\")\n",
    "    print(tab.to_string(index=False))\n",
    "    tab.to_csv(ARTIF_DIR/f\"calibracion_deciles_{name}.csv\", index=False)\n",
    "    return tab\n",
    "\n",
    "_ = decile_calibration(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) FUNCIÓN DE SCORING FUTURO (para data no vista)\n",
    "# ============================================================\n",
    "def score_future(df_nuevo_raw: pd.DataFrame, artif_path=ARTIF_DIR/\"modelo_calibrado.joblib\", target_col=TARGET,\n",
    "                 export_csv=True):\n",
    "    \"\"\"Aplica el mismo pipeline a df_nuevo. Si trae label, evalúa; si no, solo predice.\"\"\"\n",
    "    bundle = joblib.load(artif_path)\n",
    "    model  = bundle[\"model_calibrado\"]\n",
    "    cols_ok = bundle[\"columns_after_prune\"]\n",
    "    num_final, cat_final = bundle[\"num_final\"], bundle[\"cat_final\"]\n",
    "\n",
    "    df_nuevo = parse_and_features(df_nuevo_raw)\n",
    "    Xn = df_nuevo[num_final + cat_final].copy()\n",
    "    # Alinear columnas esperadas + deduplicar por si acaso\n",
    "    Xn = Xn.reindex(columns=cols_ok, fill_value=np.nan)\n",
    "    Xn = Xn.loc[:, ~Xn.columns.duplicated(keep='first')]\n",
    "    proba1 = model.predict_proba(Xn)[:,1]\n",
    "    proba0 = 1 - proba1\n",
    "\n",
    "    # Resumen probabilidades (ambas clases)\n",
    "    print(\"\\n[SCORING] Resumen probabilidades:\")\n",
    "    print(f\"mean(p0)= {proba0.mean():.3f} | mean(p1)= {proba1.mean():.3f} | min/max p1= {proba1.min():.3f}/{proba1.max():.3f}\")\n",
    "\n",
    "    if target_col in df_nuevo.columns:\n",
    "        y_true = df_nuevo[target_col].astype(int)\n",
    "        _ = evaluate_proba(y_true, proba1, name=\"DF_NUEVO\")\n",
    "        operating_points(y_true, proba1, name=\"DF_NUEVO\")\n",
    "        _ = decile_calibration(y_true, proba1, name=\"DF_NUEVO\")\n",
    "    else:\n",
    "        print(\"df_nuevo sin target: se devuelven solo probabilidades.\")\n",
    "\n",
    "    out = pd.DataFrame({\"p_no_perdida\": proba0, \"p_perdida\": proba1})\n",
    "    if export_csv:\n",
    "        out_path = ARTIF_DIR/\"scoring_df_nuevo.csv\"\n",
    "        out.to_csv(out_path, index=False)\n",
    "        print(f\"Scoring exportado a {out_path}\")\n",
    "    return out\n",
    "\n",
    "# ------------- QUICK TEST -------------\n",
    "# Simular \"futuro real\" con el 20% más reciente:\n",
    "# df_nuevo = clientes.loc[clientes['FechaEvento_dt'] > cutoff].copy()\n",
    "# _ = score_future(df_nuevo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26df9f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SCORING] Resumen probabilidades:\n",
      "mean(p0)= 0.800 | mean(p1)= 0.200 | min/max p1= 0.000/0.846\n",
      "[DF_NUEVO] ROC-AUC=0.829 | PR-AUC=0.539 | Brier=0.124\n",
      "[DF_NUEVO] Base rate y=1: 0.207 | mean(p1)=0.200 | mean(p0)=0.800\n",
      "[DF_NUEVO] best-F1=0.558 @ thr=0.205\n",
      "[DF_NUEVO] ConfMatrix @thr=0.205:\n",
      " [[16929  6362]\n",
      " [ 1291  4806]]\n",
      "[DF_NUEVO] Report @thr=0.205:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.929     0.727     0.816     23291\n",
      "           1      0.430     0.788     0.557      6097\n",
      "\n",
      "    accuracy                          0.740     29388\n",
      "   macro avg      0.680     0.758     0.686     29388\n",
      "weighted avg      0.826     0.740     0.762     29388\n",
      "\n",
      "\n",
      "[DF_NUEVO] Puntos de operación sugeridos:\n",
      " - maxF1     : thr=0.205 | precision=0.436 | recall=0.776 | F1=0.558\n",
      " - prec>=0.6 : thr=0.448 | precision=0.667 | recall=0.322 | F1=0.434\n",
      " - rec>=0.7  : thr=0.225 | precision=0.460 | recall=0.710 | F1=0.558\n",
      "\n",
      "[DF_NUEVO] Calibración por deciles (p_mean vs y_rate):\n",
      "           index   p_mean   y_rate    n\n",
      "(-0.001, 0.0157] 0.010942 0.011472 4620\n",
      "(0.0157, 0.0255] 0.025154 0.025624 1522\n",
      "(0.0255, 0.0436] 0.039738 0.041992 3072\n",
      "(0.0436, 0.0693] 0.064325 0.065875 2778\n",
      " (0.0693, 0.132] 0.104682 0.105942 2945\n",
      "  (0.132, 0.197] 0.164798 0.175198 3282\n",
      "  (0.197, 0.249] 0.232322 0.306384 2882\n",
      "  (0.249, 0.376] 0.291333 0.358911 2424\n",
      "  (0.376, 0.452] 0.446490 0.375206 3033\n",
      "  (0.452, 0.846] 0.671491 0.676678 2830\n",
      "Scoring exportado a artifacts_modelo/scoring_df_nuevo.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------- QUICK TEST -------------\n",
    "# Simular \"futuro real\" con el 20% más reciente:\n",
    "df_nuevo = clientes.loc[clientes['FechaEvento_dt'] > cutoff].copy()\n",
    "_ = score_future(df_nuevo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9296f003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "---3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0340c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SHAPE crudo: (146939, 30)\n",
      ">>> Columnas (primeras 20): ['IdentificadorCliente', 'FechaEvento', 'UsabilidadCupo', 'CategoriaPrincipalCredito', 'DiasMaximosMoraCreditosGenerados', 'NumeroCreditosGPrevius', 'NumeroCreditosGCanalFPrevius', 'NumeroCreditosGEstadoActivosPrevius', 'NumeroCreditosGEstadoPagadosPrevius', 'NumeroCreditosGCanalVPrevius', 'NumeroCreditosLPrevius', 'NumeroCreditosLEstadoActivosPrevius', 'NumeroCreditosLEstadoPagadosPrevius', 'FechaVinculacionCliente', 'FechaPrimerUso', 'FechaUltimoUso', 'TotalPagosEfectuadosGlobalmentePrevius', 'TotalPagosEfectuadosLocalmentePrevius', 'CodigoAlmacenEntregaTC', 'CodigoMunicipioEntregaTC']\n",
      "\n",
      ">>> Construyendo features (sin fuga) ...\n",
      "\n",
      "===================== EDA PREVIA (SIN FUGA) =====================\n",
      "Shape de X: (146939, 65) | y rate (1)= 0.226\n",
      "Rango de fechas (FechaEvento_dt): 2022-05-01 → 2023-10-31\n",
      "\n",
      "[Balance de clases]\n",
      "                 count    pct\n",
      "PerdidaCartera               \n",
      "no_perdida      113803  0.774\n",
      "perdida          33136  0.226\n",
      "\n",
      "[Resumen por columna] (primeras 30 filas)\n",
      "                                  columna    dtype  %nulos  n_unicos                                                      top5_valores\n",
      "                              ScoreBucket category     0.0         4 {'alto': 41836, 'medio': 40654, 'bajo': 40652, 'sin_info': 23797}\n",
      "                             CupoAprobado  float64     0.4       115                                                                {}\n",
      "                       DiasDesdeUltimoUso  float64     0.0      1096                                                                {}\n",
      "                                     Edad  float64     0.0        76                                                                {}\n",
      "                      MesesDesdePrimerUso  float64     0.0      2901                                                                {}\n",
      "                    MesesDesdeVinculacion  float64     0.0      2366                                                                {}\n",
      "             NumeroCreditosGCanalFPrevius  float64     0.0        76                                                                {}\n",
      "             NumeroCreditosGCanalVPrevius  float64     0.0         6                                                                {}\n",
      "      NumeroCreditosGEstadoActivosPrevius  float64     0.0         6                                                                {}\n",
      "      NumeroCreditosGEstadoPagadosPrevius  float64     0.0        76                                                                {}\n",
      "                   NumeroCreditosGPrevius  float64     0.0        77                                                                {}\n",
      "      NumeroCreditosLEstadoActivosPrevius  float64     0.0         2                                                                {}\n",
      "      NumeroCreditosLEstadoPagadosPrevius  float64     0.0         4                                                                {}\n",
      "                   NumeroCreditosLPrevius  float64     0.0         5                                                                {}\n",
      "                   NumeroIntentosFallidos  float64     0.0        43                                                                {}\n",
      "                          ScoreCrediticio  float64     0.0       883                                                                {}\n",
      "   TotalPagosEfectuadosGlobalmentePrevius  float64     0.0       220                                                                {}\n",
      "    TotalPagosEfectuadosLocalmentePrevius  float64     0.0        12                                                                {}\n",
      "                           UsabilidadCupo  float64     0.0    101998                                                                {}\n",
      "                   creditos_activos_ratio  float64     0.0       554                                                                {}\n",
      "                         log_CupoAprobado  float64     0.0       114                                                                {}\n",
      "                 ratio_pagos_local_global  float64     0.0      1628                                                                {}\n",
      "                    Flag_CupoAprobado_NaN    int64     0.0         2                                                                {}\n",
      "           Flag_DiasDesdeUltimoUso_Capped    int64     0.0         2                                                                {}\n",
      "              Flag_DiasDesdeUltimoUso_NaN    int64     0.0         1                                                                {}\n",
      "Flag_DiasMaximosMoraCreditosGenerados_NaN    int64     0.0         2                                                                {}\n",
      "                            Flag_Edad_NaN    int64     0.0         2                                                                {}\n",
      "                            Flag_Edad_Out    int64     0.0         2                                                                {}\n",
      "             Flag_MesesDesdePrimerUso_NaN    int64     0.0         1                                                                {}\n",
      "        Flag_MesesDesdeVinculacion_Capped    int64     0.0         2                                                                {}\n",
      "\n",
      "[Correlación numéricas vs target] (top 20)\n",
      "NumeroCreditosGEstadoActivosPrevius                0.400\n",
      "creditos_activos_ratio                             0.396\n",
      "NumeroCreditosLEstadoActivosPrevius                0.216\n",
      "NumeroCreditosLPrevius                             0.201\n",
      "ratio_pagos_local_global                           0.182\n",
      "NumeroCreditosLEstadoPagadosPrevius                0.164\n",
      "Flag_NumeroCreditosGEstadoActivosPrevius_Capped    0.151\n",
      "Flag_PrimerUsoTemu                                 0.145\n",
      "Flag_TotalPagosEfectuadosLocalmentePrevius_NaN     0.137\n",
      "Flag_TotalPagosEfectuadosGlobalmentePrevius_NaN    0.137\n",
      "TotalPagosEfectuadosLocalmentePrevius              0.125\n",
      "Flag_DiasMaximosMoraCreditosGenerados_NaN          0.116\n",
      "UsabilidadCupo                                     0.114\n",
      "Flag_NumeroCreditosLEstadoActivosPrevius_Capped    0.101\n",
      "Flag_NumeroCreditosGPrevius_NaN                    0.101\n",
      "Flag_NumeroCreditosLEstadoPagadosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosLEstadoActivosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGEstadoPagadosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGEstadoActivosPrevius_NaN       0.101\n",
      "Flag_NumeroCreditosGCanalVPrevius_NaN              0.101\n",
      "\n",
      "[Correlación numéricas vs target] (bottom 20)\n",
      "Flag_NumeroCreditosGPrevius_Capped                   -0.026\n",
      "Flag_NumeroCreditosGCanalFPrevius_Capped             -0.027\n",
      "Flag_TotalPagosEfectuadosGlobalmentePrevius_Capped   -0.028\n",
      "Flag_NumeroCreditosGEstadoPagadosPrevius_Capped      -0.029\n",
      "Flag_PrimerUsoAntesVinc                              -0.031\n",
      "MesesDesdePrimerUso                                  -0.046\n",
      "DiasDesdeUltimoUso                                   -0.048\n",
      "ScoreSinInfo                                         -0.056\n",
      "Edad                                                 -0.069\n",
      "CupoAprobado                                         -0.084\n",
      "NumeroCreditosGPrevius                               -0.087\n",
      "NumeroCreditosGCanalFPrevius                         -0.088\n",
      "TotalPagosEfectuadosGlobalmentePrevius               -0.098\n",
      "MesesDesdeVinculacion                                -0.101\n",
      "log_CupoAprobado                                     -0.102\n",
      "NumeroCreditosGEstadoPagadosPrevius                  -0.112\n",
      "Flag_UltimoUsoPosterior                                 NaN\n",
      "Flag_MesesDesdeVinculacion_NaN                          NaN\n",
      "Flag_MesesDesdePrimerUso_NaN                            NaN\n",
      "Flag_DiasDesdeUltimoUso_NaN                             NaN\n",
      "\n",
      "[Distribución Genero → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "Genero                             \n",
      "Masculino            0.753    0.247\n",
      "Desconocido          0.756    0.244\n",
      "Femenino             0.801    0.199\n",
      "\n",
      "[Distribución TipoMunicipioEntregaTC → proporción de pérdida por categoría]\n",
      "PerdidaCartera          no_perdida  perdida\n",
      "TipoMunicipioEntregaTC                     \n",
      "VIRTUAL                      0.722    0.278\n",
      "INTERMEDIO                   0.768    0.232\n",
      "PRINCIPAL                    0.796    0.204\n",
      "GRANDE                       0.816    0.184\n",
      "RURAL                        0.825    0.175\n",
      "PEQUEÑO                      0.837    0.163\n",
      "POBLADO                      0.839    0.161\n",
      "Desconocido                  0.940    0.060\n",
      "\n",
      "[Distribución CanalMunicipioEntregaTC → proporción de pérdida por categoría]\n",
      "PerdidaCartera           no_perdida  perdida\n",
      "CanalMunicipioEntregaTC                     \n",
      "Desconocido                   0.312    0.688\n",
      "Virtual                       0.722    0.278\n",
      "Fisico                        0.805    0.195\n",
      "\n",
      "[Distribución UsoAppWeb → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "UsoAppWeb                          \n",
      "App                  0.763    0.237\n",
      "Web                  0.775    0.225\n",
      "Desconocido          0.807    0.193\n",
      "\n",
      "[Distribución CategoriaPrincipalCredito → proporción de pérdida por categoría]\n",
      "PerdidaCartera               no_perdida  perdida\n",
      "CategoriaPrincipalCredito                       \n",
      "alimentos-y-bebidas               0.455    0.545\n",
      "pines-virtuales                   0.675    0.325\n",
      "bebes12255                        0.689    0.311\n",
      "ropa-y-accesorios                 0.695    0.305\n",
      "camaras-y-accesorios              0.709    0.291\n",
      "otras-categorias                  0.723    0.277\n",
      "juegos-y-juguetes                 0.732    0.268\n",
      "relojes-y-joyas                   0.735    0.265\n",
      "electronica,-audio-y-video        0.739    0.261\n",
      "accesorios-para-vehiculos         0.746    0.254\n",
      "celulares-y-telefonos             0.747    0.253\n",
      "cuidado-personal                  0.748    0.252\n",
      "arte,-papeleria-y-merceria        0.749    0.251\n",
      "electrodomesticos                 0.750    0.250\n",
      "computacion                       0.758    0.242\n",
      "consolas-y-videojuegos            0.763    0.237\n",
      "herramientas-y-construccion       0.764    0.236\n",
      "OtrosRare                         0.769    0.231\n",
      "deportes-y-fitness                0.785    0.215\n",
      "belleza-y-cuidado-personal        0.787    0.213\n",
      "animales-y-mascotas               0.787    0.213\n",
      "hogar-y-muebles                   0.789    0.211\n",
      "salud-y-equipamiento-medico       0.805    0.195\n",
      "Desconocido                       0.840    0.160\n",
      "\n",
      "[Distribución ScoreBucket → proporción de pérdida por categoría]\n",
      "PerdidaCartera  no_perdida  perdida\n",
      "ScoreBucket                        \n",
      "bajo                 0.686    0.314\n",
      "medio                0.757    0.243\n",
      "sin_info             0.828    0.172\n",
      "alto                 0.847    0.153\n",
      "\n",
      "================= FIN EDA PREVIA (SIGUE MODELADO) =================\n",
      ">>> Sin columnas duplicadas en X.\n",
      ">>> Poda de columnas casi-constantes: ['Flag_UltimoUsoPosterior', 'Flag_MesesDesdeVinculacion_NaN', 'Flag_MesesDesdePrimerUso_NaN', 'Flag_DiasDesdeUltimoUso_NaN']\n",
      "\n",
      "=== Resumen columnas finales (previas al modelado) ===\n",
      "Numéricas: 54 | Categóricas: 7\n",
      "X shape: (146939, 61) | y rate (1): 0.226\n",
      "FechaEvento_dt rango: 2022-05-01 → 2023-10-31\n",
      "\n",
      ">>> Walk-forward CV (sin fuga):\n",
      "  - Split 1: train=(88163, 61), valid=(58776, 61), cutoff=2023-04-26\n",
      "[Logit+Cal (WF1)] ROC-AUC=0.558 | PR-AUC=0.284 | Brier=0.181\n",
      "[Logit+Cal (WF1)] Base rate y=1: 0.239 | mean(p1)=0.239 | mean(p0)=0.761\n",
      "[Logit+Cal (WF1)] best-F1=0.388 @ thr=0.191\n",
      "[Logit+Cal (WF1)] ConfMatrix @thr=0.191:\n",
      " [[ 2085 42651]\n",
      " [  403 13637]]\n",
      "[Logit+Cal (WF1)] Report @thr=0.191:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.838     0.047     0.088     44736\n",
      "           1      0.242     0.971     0.388     14040\n",
      "\n",
      "    accuracy                          0.267     58776\n",
      "   macro avg      0.540     0.509     0.238     58776\n",
      "weighted avg      0.696     0.267     0.160     58776\n",
      "\n",
      "[HGB+Cal (WF1)] ROC-AUC=0.849 | PR-AUC=0.648 | Brier=0.124\n",
      "[HGB+Cal (WF1)] Base rate y=1: 0.239 | mean(p1)=0.239 | mean(p0)=0.761\n",
      "[HGB+Cal (WF1)] best-F1=0.619 @ thr=0.291\n",
      "[HGB+Cal (WF1)] ConfMatrix @thr=0.291:\n",
      " [[36894  7842]\n",
      " [ 4230  9810]]\n",
      "[HGB+Cal (WF1)] Report @thr=0.291:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.897     0.825     0.859     44736\n",
      "           1      0.556     0.699     0.619     14040\n",
      "\n",
      "    accuracy                          0.795     58776\n",
      "   macro avg      0.726     0.762     0.739     58776\n",
      "weighted avg      0.816     0.795     0.802     58776\n",
      "\n",
      "  - Split 2: train=(102857, 61), valid=(44082, 61), cutoff=2023-06-11\n",
      "[Logit+Cal (WF2)] ROC-AUC=0.569 | PR-AUC=0.285 | Brier=0.176\n",
      "[Logit+Cal (WF2)] Base rate y=1: 0.230 | mean(p1)=0.230 | mean(p0)=0.770\n",
      "[Logit+Cal (WF2)] best-F1=0.376 @ thr=0.175\n",
      "[Logit+Cal (WF2)] ConfMatrix @thr=0.175:\n",
      " [[ 1564 32387]\n",
      " [  297  9834]]\n",
      "[Logit+Cal (WF2)] Report @thr=0.175:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.840     0.046     0.087     33951\n",
      "           1      0.233     0.971     0.376     10131\n",
      "\n",
      "    accuracy                          0.259     44082\n",
      "   macro avg      0.537     0.508     0.232     44082\n",
      "weighted avg      0.701     0.259     0.154     44082\n",
      "\n",
      "[HGB+Cal (WF2)] ROC-AUC=0.844 | PR-AUC=0.615 | Brier=0.124\n",
      "[HGB+Cal (WF2)] Base rate y=1: 0.230 | mean(p1)=0.230 | mean(p0)=0.770\n",
      "[HGB+Cal (WF2)] best-F1=0.604 @ thr=0.294\n",
      "[HGB+Cal (WF2)] ConfMatrix @thr=0.294:\n",
      " [[27730  6221]\n",
      " [ 3062  7069]]\n",
      "[HGB+Cal (WF2)] Report @thr=0.294:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.901     0.817     0.857     33951\n",
      "           1      0.532     0.698     0.604     10131\n",
      "\n",
      "    accuracy                          0.789     44082\n",
      "   macro avg      0.716     0.757     0.730     44082\n",
      "weighted avg      0.816     0.789     0.798     44082\n",
      "\n",
      "  - Split 3: train=(117551, 61), valid=(29388, 61), cutoff=2023-07-29\n",
      "[Logit+Cal (WF3)] ROC-AUC=0.589 | PR-AUC=0.275 | Brier=0.163\n",
      "[Logit+Cal (WF3)] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[Logit+Cal (WF3)] best-F1=0.358 @ thr=0.227\n",
      "[Logit+Cal (WF3)] ConfMatrix @thr=0.227:\n",
      " [[13086 10205]\n",
      " [ 2545  3552]]\n",
      "[Logit+Cal (WF3)] Report @thr=0.227:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.837     0.562     0.672     23291\n",
      "           1      0.258     0.583     0.358      6097\n",
      "\n",
      "    accuracy                          0.566     29388\n",
      "   macro avg      0.548     0.572     0.515     29388\n",
      "weighted avg      0.717     0.566     0.607     29388\n",
      "\n",
      "[HGB+Cal (WF3)] ROC-AUC=0.839 | PR-AUC=0.557 | Brier=0.120\n",
      "[HGB+Cal (WF3)] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[HGB+Cal (WF3)] best-F1=0.575 @ thr=0.265\n",
      "[HGB+Cal (WF3)] ConfMatrix @thr=0.265:\n",
      " [[18643  4648]\n",
      " [ 1786  4311]]\n",
      "[HGB+Cal (WF3)] Report @thr=0.265:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.800     0.853     23291\n",
      "           1      0.481     0.707     0.573      6097\n",
      "\n",
      "    accuracy                          0.781     29388\n",
      "   macro avg      0.697     0.754     0.713     29388\n",
      "weighted avg      0.823     0.781     0.795     29388\n",
      "\n",
      "\n",
      "Logit — Walk-forward CV:\n",
      "                         cutoff   roc_auc    pr_auc     brier       thr\n",
      "0 2023-04-26 00:30:52.808999936  0.558101  0.283581  0.180803  0.190750\n",
      "1 2023-06-11 16:14:11.783000064  0.569474  0.284715  0.175720  0.175010\n",
      "2 2023-07-29 19:52:43.941999872  0.588571  0.275172  0.162625  0.227073\n",
      "Logit — medias: ROC-AUC=0.572 | PR-AUC=0.281 | Brier=0.173\n",
      "\n",
      "HGB — Walk-forward CV:\n",
      "                         cutoff   roc_auc    pr_auc     brier       thr\n",
      "0 2023-04-26 00:30:52.808999936  0.848629  0.647578  0.123772  0.290625\n",
      "1 2023-06-11 16:14:11.783000064  0.843766  0.614984  0.124089  0.294118\n",
      "2 2023-07-29 19:52:43.941999872  0.838577  0.557450  0.120149  0.264672\n",
      "HGB — medias:   ROC-AUC=0.844 | PR-AUC=0.607 | Brier=0.123\n",
      "\n",
      ">>> Modelo elegido por PR-AUC medio: HGB\n",
      "\n",
      ">>> Holdout temporal: train=(117551, 61), holdout=(29388, 61), corte=2023-07-29\n",
      ">>> Checks anti-fuga OK: sin solapes y split temporal correcto.\n",
      "[HOLDOUT-Logit] ROC-AUC=0.589 | PR-AUC=0.275 | Brier=0.163\n",
      "[HOLDOUT-Logit] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[HOLDOUT-Logit] best-F1=0.358 @ thr=0.227\n",
      "[HOLDOUT-Logit] ConfMatrix @thr=0.227:\n",
      " [[13086 10205]\n",
      " [ 2545  3552]]\n",
      "[HOLDOUT-Logit] Report @thr=0.227:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.837     0.562     0.672     23291\n",
      "           1      0.258     0.583     0.358      6097\n",
      "\n",
      "    accuracy                          0.566     29388\n",
      "   macro avg      0.548     0.572     0.515     29388\n",
      "weighted avg      0.717     0.566     0.607     29388\n",
      "\n",
      "\n",
      "[HOLDOUT-Logit] Puntos de operación sugeridos:\n",
      " - maxF1     : thr=0.227 | precision=0.258 | recall=0.583 | F1=0.358\n",
      " - prec>=0.6 : thr=0.254 | precision=1.000 | recall=0.000 | F1=0.000\n",
      " - rec>=0.7  : thr=0.214 | precision=0.235 | recall=0.701 | F1=0.352\n",
      "[HOLDOUT-HGB] ROC-AUC=0.839 | PR-AUC=0.557 | Brier=0.120\n",
      "[HOLDOUT-HGB] Base rate y=1: 0.207 | mean(p1)=0.207 | mean(p0)=0.793\n",
      "[HOLDOUT-HGB] best-F1=0.575 @ thr=0.265\n",
      "[HOLDOUT-HGB] ConfMatrix @thr=0.265:\n",
      " [[18643  4648]\n",
      " [ 1786  4311]]\n",
      "[HOLDOUT-HGB] Report @thr=0.265:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.800     0.853     23291\n",
      "           1      0.481     0.707     0.573      6097\n",
      "\n",
      "    accuracy                          0.781     29388\n",
      "   macro avg      0.697     0.754     0.713     29388\n",
      "weighted avg      0.823     0.781     0.795     29388\n",
      "\n",
      "\n",
      "[HOLDOUT-HGB] Puntos de operación sugeridos:\n",
      " - maxF1     : thr=0.265 | precision=0.504 | recall=0.669 | F1=0.575\n",
      " - prec>=0.6 : thr=0.448 | precision=0.666 | recall=0.327 | F1=0.439\n",
      " - rec>=0.7  : thr=0.250 | precision=0.481 | recall=0.707 | F1=0.573\n",
      "\n",
      "[HOLDOUT-HGB] Barrido de umbrales (métricas por clase y confusión):\n",
      "  thr  prec_1  rec_1  F1_1  prec_0  rec_0   TP   FP   FN    TN\n",
      "0.200   0.426  0.804 0.557   0.933  0.716 4905 6604 1192 16687\n",
      "0.250   0.477  0.714 0.572   0.914  0.795 4356 4783 1741 18508\n",
      "0.265   0.504  0.669 0.575   0.905  0.828 4081 4009 2016 19282\n",
      "0.300   0.513  0.654 0.575   0.902  0.838 3988 3780 2109 19511\n",
      "0.400   0.546  0.590 0.567   0.890  0.871 3600 2994 2497 20297\n",
      "0.500   0.693  0.300 0.419   0.840  0.965 1831  811 4266 22480\n",
      "\n",
      "[Punto auto] Máxima F1 clase 1: thr≈0.265 | precision=0.504 | recall=0.669 | F1=0.575\n",
      "\n",
      "[Tabla negocio] @thr=0.265\n",
      "                KPI  conteo  tasa_sobre_total\n",
      "    TP (detectados)    4311             0.147\n",
      "FP (falsas alertas)    4648             0.158\n",
      " FN (no detectados)    1786             0.061\n",
      "         TN (sanos)   18643             0.634\n",
      "\n",
      ">>> Artefactos guardados en artifacts_modelo/modelo_calibrado.joblib\n",
      "\n",
      "[HOLDOUT-HGB] Calibración por deciles (p_mean vs y_rate):\n",
      "           index   p_mean   y_rate    n\n",
      "(-0.001, 0.0157] 0.010896 0.010896 4497\n",
      "(0.0157, 0.0255] 0.025153 0.025153 1471\n",
      "(0.0255, 0.0436] 0.039778 0.039778 3067\n",
      "(0.0436, 0.0693] 0.064372 0.064372 2905\n",
      " (0.0693, 0.132] 0.103796 0.103796 2977\n",
      "  (0.132, 0.197] 0.164754 0.164754 2962\n",
      "  (0.197, 0.265] 0.241006 0.241006 3419\n",
      "  (0.265, 0.448] 0.409572 0.409572 5098\n",
      "  (0.448, 0.452] 0.452174 0.452174  115\n",
      "  (0.452, 0.846] 0.674661 0.674661 2877\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODELO DE RIESGO — VALIDACIÓN TEMPORAL ESTRICTA (SIN FUGA)\n",
    "# ============================================================\n",
    "# Requiere: pandas, numpy, scikit-learn, joblib\n",
    "# Supone que 'clientes' (crudo) está disponible en memoria.\n",
    "#   - columnas de fecha: FechaEvento, FechaVinculacionCliente, FechaUltimoUso, FechaPrimerUso\n",
    "#   - target: PerdidaCartera (0/1)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss,\n",
    "    classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) CONFIG\n",
    "# -----------------------------\n",
    "TARGET = \"PerdidaCartera\"\n",
    "RANDOM_STATE = 42\n",
    "ARTIF_DIR = Path(\"./artifacts_modelo\"); ARTIF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# ============================================================\n",
    "# 1) INGESTA (usa tu carga real). Aseguramos target y forma.\n",
    "# ============================================================\n",
    "# EJEMPLO (descomenta si lo necesitas):\n",
    "# clientes = pd.read_parquet(\"data/clientes.parquet\")\n",
    "\n",
    "assert TARGET in clientes.columns, f\"No encuentro columna target '{TARGET}' en 'clientes'\"\n",
    "print(\">>> SHAPE crudo:\", clientes.shape)\n",
    "print(\">>> Columnas (primeras 20):\", list(clientes.columns)[:20])\n",
    "\n",
    "# ============================================================\n",
    "# 2) FEATURE ENGINEERING — SIN FUGA\n",
    "# ============================================================\n",
    "def parse_and_features(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # --- Fechas\n",
    "    df['FechaEvento_dt'] = (\n",
    "        pd.to_datetime(df['FechaEvento'], errors='coerce', utc=True)\n",
    "          .dt.tz_convert(None)\n",
    "    )\n",
    "    df['FechaVinculacionCliente_dt'] = pd.to_datetime(\n",
    "        df['FechaVinculacionCliente'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaUltimoUso_dt'] = pd.to_datetime(\n",
    "        df['FechaUltimoUso'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaPrimerUso_dt'] = pd.to_datetime(\n",
    "        df['FechaPrimerUso'], errors='coerce',\n",
    "        origin='1904-01-01', unit='D'\n",
    "    )\n",
    "\n",
    "    # Corrección conservadora PrimerUso\n",
    "    df['Flag_PrimerUsoAntesVinc'] = (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt']).astype(int)\n",
    "    mask_bad = df['FechaPrimerUso_dt'].isna() | (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt'])\n",
    "    df.loc[mask_bad,  'FechaPrimerUso_corr'] = df.loc[mask_bad,  'FechaVinculacionCliente_dt']\n",
    "    df.loc[~mask_bad, 'FechaPrimerUso_corr'] = df.loc[~mask_bad, 'FechaPrimerUso_dt']\n",
    "\n",
    "    # Diferencias seguras\n",
    "    def safe_months(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d / 30.0\n",
    "\n",
    "    def safe_days(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d\n",
    "\n",
    "    df['MesesDesdeVinculacion'] = safe_months(df['FechaEvento_dt'], df['FechaVinculacionCliente_dt'])\n",
    "    df['MesesDesdePrimerUso']   = safe_months(df['FechaEvento_dt'], df['FechaPrimerUso_corr'])\n",
    "    df['DiasDesdeUltimoUso']    = safe_days(df['FechaEvento_dt'],  df['FechaUltimoUso_dt'])\n",
    "\n",
    "    # --- Usabilidad\n",
    "    df['UsabilidadCupo'] = pd.to_numeric(df['UsabilidadCupo'], errors='coerce')\n",
    "    df['Flag_Usab_NaN']    = df['UsabilidadCupo'].isna().astype(int)\n",
    "    df['Flag_Usab_Outlier']= ((df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2)).astype(int)\n",
    "    df.loc[(df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2), 'UsabilidadCupo'] = np.nan\n",
    "    df['UsabilidadCupo']   = df['UsabilidadCupo'].fillna(df['UsabilidadCupo'].median())\n",
    "\n",
    "    # --- Flags de fechas\n",
    "    df['Flag_UltimoUsoPosterior'] = (df['FechaUltimoUso_dt'] > df['FechaEvento_dt']).fillna(False).astype(int)\n",
    "\n",
    "    # --- Numéricas con nulos —> flags + imputación conservadora\n",
    "    num_cols_candidates = [\n",
    "        'DiasMaximosMoraCreditosGenerados',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','CupoAprobado','ScoreCrediticio','Edad',\n",
    "        'MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso'\n",
    "    ]\n",
    "    for c in num_cols_candidates:\n",
    "        if c in df.columns:\n",
    "            df[f'Flag_{c}_NaN'] = df[c].isna().astype(int)\n",
    "            if c.startswith('NumeroCreditos') or c.startswith('TotalPagos'):\n",
    "                df[c] = df[c].fillna(0)\n",
    "            elif c in ['DiasMaximosMoraCreditosGenerados','Edad','NumeroIntentosFallidos']:\n",
    "                df[c] = df[c].fillna(0)\n",
    "\n",
    "    # --- Score & Cupo\n",
    "    df['ScoreSinInfo'] = (df['ScoreCrediticio'] == 0).astype(int)\n",
    "    if df['ScoreCrediticio'].isna().any():\n",
    "        med_pos = df.loc[df['ScoreCrediticio']>0, 'ScoreCrediticio'].median()\n",
    "        df['ScoreCrediticio'] = df['ScoreCrediticio'].fillna(med_pos)\n",
    "\n",
    "    df['log_CupoAprobado'] = np.log1p(df['CupoAprobado'])\n",
    "    df['log_CupoAprobado'] = df['log_CupoAprobado'].fillna(df['log_CupoAprobado'].median())\n",
    "\n",
    "    # --- Categóricas limpias\n",
    "    for c in ['CategoriaPrincipalCredito','UsoAppWeb','Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna('Desconocido')\n",
    "    df['Genero'] = df['Genero'].replace({27:'Desconocido'})\n",
    "    df['TipoMunicipioEntregaTC'] = df['TipoMunicipioEntregaTC'].replace({'PEQUEÃ‘O':'PEQUEÑO'}).fillna('Desconocido')\n",
    "\n",
    "    # --- Rango de Edad\n",
    "    df['Flag_Edad_Out'] = (~df['Edad'].between(18, 100, inclusive='both')).fillna(False).astype(int)\n",
    "    df.loc[df['Flag_Edad_Out']==1, 'Edad'] = np.nan\n",
    "    df['Edad'] = df['Edad'].fillna(df['Edad'].median())\n",
    "\n",
    "    # --- Features derivadas clave\n",
    "    if 'Flag_PrimerUsoTemu' not in df.columns and 'NumeroCreditosGPrevius' in df.columns:\n",
    "        df['Flag_PrimerUsoTemu'] = (df['NumeroCreditosGPrevius'] == 0).astype(int)\n",
    "\n",
    "    df['ratio_pagos_local_global'] = (\n",
    "        df['TotalPagosEfectuadosLocalmentePrevius'].fillna(0) /\n",
    "        (df['TotalPagosEfectuadosGlobalmentePrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    df['creditos_activos_ratio'] = (\n",
    "        df['NumeroCreditosGEstadoActivosPrevius'].fillna(0) /\n",
    "        (df['NumeroCreditosGPrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    for c in ['ratio_pagos_local_global','creditos_activos_ratio']:\n",
    "        df[c] = df[c].replace([np.inf,-np.inf], np.nan).fillna(0).clip(0,1)\n",
    "\n",
    "    df['Flag_CanalVirtual'] = (\n",
    "        (df['CanalMunicipioEntregaTC'].astype(str).str.lower()=='virtual') |\n",
    "        (df['TipoMunicipioEntregaTC'].astype(str).str.upper()=='VIRTUAL')\n",
    "    ).astype(int)\n",
    "\n",
    "    # --- Score negativo -> 0, más bucket\n",
    "    df['Flag_Score_Negativo'] = (df['ScoreCrediticio'] < 0).astype(int)\n",
    "    df.loc[df['ScoreCrediticio'] < 0, 'ScoreCrediticio'] = 0\n",
    "\n",
    "    df['ScoreBucket'] = 'sin_info'\n",
    "    mask_pos = df['ScoreCrediticio'] > 0\n",
    "    if mask_pos.sum() > 0:\n",
    "        b1, b2 = df.loc[mask_pos, 'ScoreCrediticio'].quantile([0.33, 0.66]).values\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] <= b1), 'ScoreBucket'] = 'bajo'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b1) & (df['ScoreCrediticio'] <= b2), 'ScoreBucket'] = 'medio'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b2), 'ScoreBucket'] = 'alto'\n",
    "    df['ScoreBucket'] = pd.Categorical(df['ScoreBucket'], categories=['sin_info','bajo','medio','alto'], ordered=True)\n",
    "\n",
    "    # --- Winsorización p99 + flags (colas largas)\n",
    "    def cap_with_flag(s, upper):\n",
    "        flag = (s > upper).astype(int)\n",
    "        return np.where(s > upper, upper, s), flag\n",
    "\n",
    "    cap_cols = [\n",
    "        'DiasDesdeUltimoUso','MesesDesdeVinculacion',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius'\n",
    "    ]\n",
    "    for c in cap_cols:\n",
    "        if c in df.columns:\n",
    "            p99 = df[c].quantile(0.99)\n",
    "            capped, flag = cap_with_flag(df[c].fillna(0), p99)\n",
    "            df[c] = capped\n",
    "            df[f'Flag_{c}_Capped'] = flag\n",
    "\n",
    "    # Agrupar categorías raras de CategoriaPrincipalCredito (<0.1%)\n",
    "    if 'CategoriaPrincipalCredito' in df.columns:\n",
    "        vc = df['CategoriaPrincipalCredito'].astype(str).value_counts(dropna=False)\n",
    "        cutoff = df.shape[0] * 0.001\n",
    "        rare_levels = vc[vc < cutoff].index\n",
    "        df['CategoriaPrincipalCredito'] = df['CategoriaPrincipalCredito'].astype(str)\n",
    "        df.loc[df['CategoriaPrincipalCredito'].isin(rare_levels), 'CategoriaPrincipalCredito'] = 'OtrosRare'\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_feature_lists(df: pd.DataFrame):\n",
    "    drop_from_features = [\n",
    "        'IdentificadorCliente','FechaEvento','FechaVinculacionCliente','FechaPrimerUso','FechaUltimoUso',\n",
    "        'FechaEvento_dt','FechaVinculacionCliente_dt','FechaPrimerUso_dt','FechaUltimoUso_dt','FechaPrimerUso_corr',\n",
    "        'CodigoAlmacenEntregaTC','CodigoAlmacenEntregaTC_str','AlmacenTop20',\n",
    "        'CodigoMunicipioEntregaTC','MunicipioCat','MunicipioTop20','MesCompra',\n",
    "        'DiasMora'\n",
    "    ]\n",
    "    num_base = [\n",
    "        'UsabilidadCupo','MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','ScoreCrediticio','ScoreSinInfo','CupoAprobado','log_CupoAprobado','Edad',\n",
    "        'Flag_Usab_NaN','Flag_Usab_Outlier','Flag_PrimerUsoAntesVinc','Flag_UltimoUsoPosterior','Flag_Edad_Out',\n",
    "        'ratio_pagos_local_global','creditos_activos_ratio','Flag_Score_Negativo'\n",
    "    ]\n",
    "    num_dyn = [c for c in df.columns if c.startswith('Flag_') and (c.endswith('_NaN') or c.endswith('_Capped'))]\n",
    "    num_final = [c for c in (num_base + num_dyn) if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    cat_final = [\n",
    "        'Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC','UsoAppWeb','CategoriaPrincipalCredito',\n",
    "        'Flag_PrimerUsoTemu','ScoreBucket'\n",
    "    ]\n",
    "    cat_final = [c for c in cat_final if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    # Evitar solape entre num y cat + forzar unicidad y orden estable\n",
    "    overlap = set(num_final) & set(cat_final)\n",
    "    if overlap:\n",
    "        print(f\">>> Aviso: {len(overlap)} columnas estaban en num y cat. Se quitan de num: {sorted(overlap)}\")\n",
    "        num_final = [c for c in num_final if c not in overlap]\n",
    "\n",
    "    num_final = list(dict.fromkeys(num_final))\n",
    "    cat_final = list(dict.fromkeys(cat_final))\n",
    "    return num_final, cat_final\n",
    "\n",
    "\n",
    "def prune_low_variance(X: pd.DataFrame):\n",
    "    low_var = [c for c in X.columns if X[c].nunique(dropna=False) <= 1]\n",
    "    if low_var:\n",
    "        print(\">>> Poda de columnas casi-constantes:\", low_var)\n",
    "        return X.drop(columns=low_var, errors='ignore'), low_var\n",
    "    else:\n",
    "        print(\">>> Poda de columnas casi-constantes: ninguna\")\n",
    "        return X, []\n",
    "\n",
    "\n",
    "def build_pipelines(cat_cols, num_cols):\n",
    "    pre_logit = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "            ]), cat_cols),\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='median'))\n",
    "            ]), num_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    logit = Pipeline(steps=[\n",
    "        ('pre', pre_logit),\n",
    "        ('clf', LogisticRegression(\n",
    "            solver='saga', penalty='l2', class_weight='balanced',\n",
    "            max_iter=800, n_jobs=-1, random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pre_hgb = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "            ('num', 'passthrough', num_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    hgb = Pipeline(steps=[\n",
    "        ('pre', pre_hgb),\n",
    "        ('clf', HistGradientBoostingClassifier(\n",
    "            learning_rate=0.07, max_leaf_nodes=31, l2_regularization=1.0,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    return logit, hgb\n",
    "\n",
    "\n",
    "def evaluate_proba(y_true, y_proba, name=\"model\"):\n",
    "    # Métricas de probas + resumen de ambos lados\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    ap  = average_precision_score(y_true, y_proba)\n",
    "    br  = brier_score_loss(y_true, y_proba)\n",
    "    print(f\"[{name}] ROC-AUC={auc:.3f} | PR-AUC={ap:.3f} | Brier={br:.3f}\")\n",
    "    print(f\"[{name}] Base rate y=1: {y_true.mean():.3f} | mean(p1)={np.mean(y_proba):.3f} | mean(p0)={np.mean(1-y_proba):.3f}\")\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    j  = np.argmax(f1)\n",
    "    best_thr = thr[j-1] if j>0 and j-1 < len(thr) else 0.5\n",
    "    y_hat = (y_proba >= best_thr).astype(int)\n",
    "    print(f\"[{name}] best-F1={f1[j]:.3f} @ thr={best_thr:.3f}\")\n",
    "    print(f\"[{name}] ConfMatrix @thr={best_thr:.3f}:\\n\", confusion_matrix(y_true, y_hat))\n",
    "    print(f\"[{name}] Report @thr={best_thr:.3f}:\\n\", classification_report(y_true, y_hat, digits=3))\n",
    "    return dict(roc_auc=auc, pr_auc=ap, brier=br, thr=best_thr)\n",
    "\n",
    "\n",
    "def operating_points(y_true, y_proba, name=\"model\"):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    pts = {}\n",
    "    # máx F1\n",
    "    j = np.argmax(f1); pts['maxF1'] = (thr[j-1] if j>0 else 0.5, p[j], r[j], f1[j])\n",
    "    # precisión >= 0.6\n",
    "    idx = np.where(p>=0.6)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(r[idx])]\n",
    "        pts['prec>=0.6'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "    # recall >= 0.7\n",
    "    idx = np.where(r>=0.7)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(p[idx])]\n",
    "        pts['rec>=0.7'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "\n",
    "    print(f\"\\n[{name}] Puntos de operación sugeridos:\")\n",
    "    for kk,(t,pp,rr,ff) in pts.items():\n",
    "        print(f\" - {kk:10s}: thr={t:.3f} | precision={pp:.3f} | recall={rr:.3f} | F1={ff:.3f}\")\n",
    "    return pts\n",
    "\n",
    "\n",
    "def walk_forward_cv(df, X, y, cat_cols, num_cols, cut_fracs=(0.6,0.7,0.8)):\n",
    "    \"\"\"Valida SIN FUGA con 3 cortes temporales (ajustable).\"\"\"\n",
    "    cutoffs = df['FechaEvento_dt'].quantile(list(cut_fracs)).values\n",
    "    rows_l, rows_h = [], []\n",
    "    logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "\n",
    "    print(\"\\n>>> Walk-forward CV (sin fuga):\")\n",
    "    for i, c in enumerate(cutoffs, 1):\n",
    "        tr_idx = df['FechaEvento_dt'] <= c\n",
    "        va_idx = df['FechaEvento_dt'] >  c\n",
    "        X_tr, X_va = X.loc[tr_idx], X.loc[va_idx]\n",
    "        y_tr, y_va = y.loc[tr_idx], y.loc[va_idx]\n",
    "        print(f\"  - Split {i}: train={X_tr.shape}, valid={X_va.shape}, cutoff={pd.Timestamp(c).date()}\")\n",
    "\n",
    "        # Logit + calibración\n",
    "        logit.fit(X_tr, y_tr)\n",
    "        cal_logit = CalibratedClassifierCV(logit, method='sigmoid', cv='prefit')\n",
    "        cal_logit.fit(X_va, y_va)\n",
    "        proba_l = cal_logit.predict_proba(X_va)[:,1]\n",
    "        m_l = evaluate_proba(y_va, proba_l, name=f\"Logit+Cal (WF{i})\")\n",
    "        rows_l.append({\"cutoff\": c, **m_l})\n",
    "\n",
    "        # HGB + sample_weight + calibración\n",
    "        sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "        hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "        cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "        cal_hgb.fit(X_va, y_va)\n",
    "        proba_h = cal_hgb.predict_proba(X_va)[:,1]\n",
    "        m_h = evaluate_proba(y_va, proba_h, name=f\"HGB+Cal (WF{i})\")\n",
    "        rows_h.append({\"cutoff\": c, **m_h})\n",
    "\n",
    "    return pd.DataFrame(rows_l), pd.DataFrame(rows_h)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CONSTRUIR DATASET LIMPIO + LISTAS DE FEATURES + EDA\n",
    "# ============================================================\n",
    "print(\"\\n>>> Construyendo features (sin fuga) ...\")\n",
    "clientes = parse_and_features(clientes)\n",
    "num_final, cat_final = build_feature_lists(clientes)\n",
    "\n",
    "X = clientes[num_final + cat_final].copy()\n",
    "y = clientes[TARGET].astype(int).copy()\n",
    "\n",
    "# 3A) EDA previa (resumen, correlaciones, crosstabs)\n",
    "print(\"\\n===================== EDA PREVIA (SIN FUGA) =====================\")\n",
    "print(f\"Shape de X: {X.shape} | y rate (1)= {y.mean():.3f}\")\n",
    "print(\"Rango de fechas (FechaEvento_dt):\",\n",
    "      str(clientes['FechaEvento_dt'].min().date()), \"→\", str(clientes['FechaEvento_dt'].max().date()))\n",
    "\n",
    "vc = y.value_counts().rename({0:'no_perdida', 1:'perdida'})\n",
    "print(\"\\n[Balance de clases]\")\n",
    "print(pd.concat([vc, (vc/vc.sum()).round(3).rename('pct')], axis=1).to_string())\n",
    "\n",
    "summary_rows = []\n",
    "for c in X.columns:\n",
    "    s = X[c]\n",
    "    dtype = s.dtype\n",
    "    pct_null = s.isnull().mean()*100\n",
    "    nuni = s.nunique(dropna=False)\n",
    "    # FIX: usar is_numeric_dtype para que no falle con CategoricalDtype\n",
    "    top5 = s.value_counts(dropna=False).head(5).to_dict() if (not is_numeric_dtype(s)) else {}\n",
    "    summary_rows.append({\n",
    "        'columna': c, 'dtype': str(dtype), '%nulos': round(pct_null,1),\n",
    "        'n_unicos': int(nuni), 'top5_valores': top5\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(['dtype','columna'])\n",
    "print(\"\\n[Resumen por columna] (primeras 30 filas)\")\n",
    "print(summary_df.head(30).to_string(index=False))\n",
    "summary_df.to_csv(ARTIF_DIR/\"eda_resumen_columnas.csv\", index=False)\n",
    "\n",
    "num_cols_for_corr = [c for c in X.columns if is_numeric_dtype(X[c]) and c != TARGET]\n",
    "if len(num_cols_for_corr) > 0:\n",
    "    corrs = X[num_cols_for_corr].corrwith(y).sort_values(ascending=False)\n",
    "    print(\"\\n[Correlación numéricas vs target] (top 20)\")\n",
    "    print(corrs.head(20).round(3).to_string())\n",
    "    print(\"\\n[Correlación numéricas vs target] (bottom 20)\")\n",
    "    print(corrs.tail(20).round(3).to_string())\n",
    "\n",
    "cat_cols_for_xtab = [c for c in X.columns if not is_numeric_dtype(X[c])]\n",
    "for c in cat_cols_for_xtab:\n",
    "    # sólo crosstab para cardinalidad moderada\n",
    "    if X[c].nunique(dropna=False) <= 25:\n",
    "        tab = pd.crosstab(X[c], y, normalize='index').rename(columns={0:'no_perdida',1:'perdida'}).round(3)\n",
    "        print(f\"\\n[Distribución {c} → proporción de pérdida por categoría]\")\n",
    "        print(tab.sort_values('perdida', ascending=False).to_string())\n",
    "\n",
    "print(\"\\n================= FIN EDA PREVIA (SIGUE MODELADO) =================\")\n",
    "\n",
    "# 3B) Limpiezas extra útiles antes de modelar\n",
    "# --- ELIMINAR COLUMNAS DUPLICADAS EN X ---\n",
    "dups_mask = X.columns.duplicated(keep='first')\n",
    "if dups_mask.any():\n",
    "    dups = pd.Series(X.columns)[dups_mask].tolist()\n",
    "    print(f\">>> Columnas duplicadas detectadas y removidas ({len(dups)}): {dups}\")\n",
    "    X = X.loc[:, ~X.columns.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\">>> Sin columnas duplicadas en X.\")\n",
    "\n",
    "# --- PODA BAJA VARIANZA ---\n",
    "X, dropped_lowvar = prune_low_variance(X)\n",
    "\n",
    "print(\"\\n=== Resumen columnas finales (previas al modelado) ===\")\n",
    "print(f\"Numéricas: {len([c for c in X.columns if c in num_final])} | Categóricas: {len([c for c in X.columns if c in cat_final])}\")\n",
    "print(\"X shape:\", X.shape, \"| y rate (1):\", y.mean().round(3))\n",
    "print(\"FechaEvento_dt rango:\", str(clientes['FechaEvento_dt'].min().date()), \"→\", str(clientes['FechaEvento_dt'].max().date()))\n",
    "\n",
    "# ============================================================\n",
    "# 4) WALK-FORWARD CV — SIN MIRAR EL FUTURO\n",
    "# ============================================================\n",
    "cat_cols = [c for c in cat_final if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "logit_cv, hgb_cv = walk_forward_cv(clientes, X, y, cat_cols, num_cols)\n",
    "\n",
    "print(\"\\nLogit — Walk-forward CV:\")\n",
    "print(logit_cv)\n",
    "print(f\"Logit — medias: ROC-AUC={logit_cv.roc_auc.mean():.3f} | PR-AUC={logit_cv.pr_auc.mean():.3f} | Brier={logit_cv.brier.mean():.3f}\")\n",
    "\n",
    "print(\"\\nHGB — Walk-forward CV:\")\n",
    "print(hgb_cv)\n",
    "print(f\"HGB — medias:   ROC-AUC={hgb_cv.roc_auc.mean():.3f} | PR-AUC={hgb_cv.pr_auc.mean():.3f} | Brier={hgb_cv.brier.mean():.3f}\")\n",
    "\n",
    "chosen = \"HGB\" if hgb_cv.pr_auc.mean() >= logit_cv.pr_auc.mean() else \"Logit\"\n",
    "print(f\"\\n>>> Modelo elegido por PR-AUC medio: {chosen}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5) HOLDOUT FINAL (FUTURO) — 20% MÁS RECIENTE + CHEQUEOS\n",
    "# ============================================================\n",
    "cutoff = clientes['FechaEvento_dt'].quantile(0.8)\n",
    "train_idx = clientes['FechaEvento_dt'] <= cutoff\n",
    "hold_idx  = clientes['FechaEvento_dt'] >  cutoff\n",
    "X_tr, X_ho = X.loc[train_idx], X.loc[hold_idx]\n",
    "y_tr, y_ho = y.loc[train_idx], y.loc[hold_idx]\n",
    "print(f\"\\n>>> Holdout temporal: train={X_tr.shape}, holdout={X_ho.shape}, corte={pd.Timestamp(cutoff).date()}\")\n",
    "\n",
    "# Chequeos anti-fuga (muy importantes)\n",
    "idx_train = set(X_tr.index); idx_hold = set(X_ho.index)\n",
    "assert idx_train.isdisjoint(idx_hold), \"Solapamiento entre train y holdout\"\n",
    "assert clientes.loc[X_tr.index, 'FechaEvento_dt'].max() <= cutoff, \"Train tiene fechas > cutoff\"\n",
    "assert clientes.loc[X_ho.index, 'FechaEvento_dt'].min() >  cutoff, \"Holdout tiene fechas <= cutoff\"\n",
    "print(\">>> Checks anti-fuga OK: sin solapes y split temporal correcto.\")\n",
    "\n",
    "logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "\n",
    "# LOGIT + calibración\n",
    "logit.fit(X_tr, y_tr)\n",
    "cal_logit = CalibratedClassifierCV(logit, method='sigmoid', cv='prefit')\n",
    "cal_logit.fit(X_ho, y_ho)\n",
    "proba_logit = cal_logit.predict_proba(X_ho)[:,1]\n",
    "_ = evaluate_proba(y_ho, proba_logit, name=\"HOLDOUT-Logit\")\n",
    "operating_points(y_ho, proba_logit, name=\"HOLDOUT-Logit\")\n",
    "\n",
    "# HGB + sample_weight + calibración (modelo principal)\n",
    "sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "cal_hgb.fit(X_ho, y_ho)\n",
    "proba_hgb = cal_hgb.predict_proba(X_ho)[:,1]\n",
    "m_hold = evaluate_proba(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "operating_points(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# --- Barrido de umbrales con métricas por clase + confusiones\n",
    "def sweep_thresholds(y_true, y_proba, thresholds=(0.20, 0.25, 0.265, 0.30, 0.40, 0.50)):\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yhat = (y_proba >= t).astype(int)\n",
    "        TN, FP, FN, TP = confusion_matrix(y_true, yhat).ravel()\n",
    "        prec1 = TP / (TP+FP) if TP+FP>0 else 0.0\n",
    "        rec1  = TP / (TP+FN) if TP+FN>0 else 0.0\n",
    "        f1    = (2*prec1*rec1/(prec1+rec1)) if (prec1+rec1)>0 else 0.0\n",
    "        prec0 = TN / (TN+FN) if TN+FN>0 else 0.0   # precisión clase 0\n",
    "        rec0  = TN / (TN+FP) if TN+FP>0 else 0.0   # recall clase 0\n",
    "        rows.append({\n",
    "            \"thr\": t,\n",
    "            \"prec_1\": round(prec1,3), \"rec_1\": round(rec1,3), \"F1_1\": round(f1,3),\n",
    "            \"prec_0\": round(prec0,3), \"rec_0\": round(rec0,3),\n",
    "            \"TP\": TP, \"FP\": FP, \"FN\": FN, \"TN\": TN\n",
    "        })\n",
    "    tab = pd.DataFrame(rows)\n",
    "    print(\"\\n[HOLDOUT-HGB] Barrido de umbrales (métricas por clase y confusión):\")\n",
    "    print(tab.to_string(index=False))\n",
    "    tab.to_csv(ARTIF_DIR/\"holdout_umbral_sweep.csv\", index=False)\n",
    "    return tab\n",
    "\n",
    "tab_thr = sweep_thresholds(y_ho, proba_hgb)\n",
    "\n",
    "# --- Punto de operación por máxima F1 (automático)\n",
    "p, r, thr = precision_recall_curve(y_ho, proba_hgb)\n",
    "f1 = 2*p*r/(p+r+1e-12)\n",
    "j  = np.argmax(f1)\n",
    "thr_star = thr[j-1] if j>0 and j-1<len(thr) else 0.5\n",
    "print(f\"\\n[Punto auto] Máxima F1 clase 1: thr≈{thr_star:.3f} | precision={p[j]:.3f} | recall={r[j]:.3f} | F1={f1[j]:.3f}\")\n",
    "\n",
    "# --- Tabla de negocio (tasas sobre total)\n",
    "def business_table(y_true, y_proba, thr):\n",
    "    yhat = (y_proba >= thr).astype(int)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_true, yhat).ravel()\n",
    "    n = len(y_true)\n",
    "    out = pd.DataFrame({\n",
    "        \"KPI\": [\"TP (detectados)\",\"FP (falsas alertas)\",\"FN (no detectados)\",\"TN (sanos)\"],\n",
    "        \"conteo\": [TP, FP, FN, TN],\n",
    "        \"tasa_sobre_total\": [round(TP/n,3), round(FP/n,3), round(FN/n,3), round(TN/n,3)]\n",
    "    })\n",
    "    print(f\"\\n[Tabla negocio] @thr={thr:.3f}\")\n",
    "    print(out.to_string(index=False))\n",
    "    out.to_csv(ARTIF_DIR/\"holdout_tabla_negocio.csv\", index=False)\n",
    "    return out\n",
    "\n",
    "_ = business_table(y_ho, proba_hgb, thr_star)\n",
    "\n",
    "# Guardar bundle de artefactos (modelo calibrado + metadatos)\n",
    "bundle = {\n",
    "    \"model_calibrado\": cal_hgb if chosen==\"HGB\" else cal_logit,\n",
    "    \"chosen\": chosen,\n",
    "    \"num_final\": num_final,\n",
    "    \"cat_final\": cat_final,\n",
    "    \"columns_after_prune\": list(X.columns),\n",
    "    \"cutoff\": cutoff\n",
    "}\n",
    "joblib.dump(bundle, ARTIF_DIR/\"modelo_calibrado.joblib\")\n",
    "print(f\"\\n>>> Artefactos guardados en {ARTIF_DIR/'modelo_calibrado.joblib'}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6) CALIBRACIÓN POR DECILES EN HOLDOUT\n",
    "# ============================================================\n",
    "def decile_calibration(y_true, y_proba, name=\"holdout\"):\n",
    "    bins = pd.qcut(y_proba, q=10, duplicates='drop')\n",
    "    tab = pd.DataFrame({\"p\":y_proba, \"y\":y_true}).groupby(bins, observed=True).agg(\n",
    "        p_mean=('p','mean'),\n",
    "        y_rate=('y','mean'),\n",
    "        n=('p','size')\n",
    "    ).reset_index().rename(columns={\"p\":\"bin\"})\n",
    "    print(f\"\\n[{name}] Calibración por deciles (p_mean vs y_rate):\")\n",
    "    print(tab.to_string(index=False))\n",
    "    tab.to_csv(ARTIF_DIR/f\"calibracion_deciles_{name}.csv\", index=False)\n",
    "    return tab\n",
    "\n",
    "_ = decile_calibration(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) FUNCIÓN DE SCORING FUTURO (para data no vista)\n",
    "# ============================================================\n",
    "def score_future(df_nuevo_raw: pd.DataFrame, artif_path=ARTIF_DIR/\"modelo_calibrado.joblib\", target_col=TARGET,\n",
    "                 export_csv=True):\n",
    "    \"\"\"Aplica el mismo pipeline a df_nuevo. Si trae label, evalúa; si no, solo predice.\"\"\"\n",
    "    bundle = joblib.load(artif_path)\n",
    "    model  = bundle[\"model_calibrado\"]\n",
    "    cols_ok = bundle[\"columns_after_prune\"]\n",
    "    num_final, cat_final = bundle[\"num_final\"], bundle[\"cat_final\"]\n",
    "\n",
    "    df_nuevo = parse_and_features(df_nuevo_raw)\n",
    "    Xn = df_nuevo[num_final + cat_final].copy()\n",
    "    # Alinear columnas esperadas + deduplicar por si acaso\n",
    "    Xn = Xn.reindex(columns=cols_ok, fill_value=np.nan)\n",
    "    Xn = Xn.loc[:, ~Xn.columns.duplicated(keep='first')]\n",
    "    proba1 = model.predict_proba(Xn)[:,1]\n",
    "    proba0 = 1 - proba1\n",
    "\n",
    "    # Resumen probabilidades (ambas clases)\n",
    "    print(\"\\n[SCORING] Resumen probabilidades:\")\n",
    "    print(f\"mean(p0)= {proba0.mean():.3f} | mean(p1)= {proba1.mean():.3f} | min/max p1= {proba1.min():.3f}/{proba1.max():.3f}\")\n",
    "\n",
    "    if target_col in df_nuevo.columns:\n",
    "        y_true = df_nuevo[target_col].astype(int)\n",
    "        _ = evaluate_proba(y_true, proba1, name=\"DF_NUEVO\")\n",
    "        operating_points(y_true, proba1, name=\"DF_NUEVO\")\n",
    "        _ = decile_calibration(y_true, proba1, name=\"DF_NUEVO\")\n",
    "    else:\n",
    "        print(\"df_nuevo sin target: se devuelven solo probabilidades.\")\n",
    "\n",
    "    out = pd.DataFrame({\"p_no_perdida\": proba0, \"p_perdida\": proba1})\n",
    "    if export_csv:\n",
    "        out_path = ARTIF_DIR/\"scoring_df_nuevo.csv\"\n",
    "        out.to_csv(out_path, index=False)\n",
    "        print(f\"Scoring exportado a {out_path}\")\n",
    "    return out\n",
    "\n",
    "# ------------- QUICK TEST -------------\n",
    "# Simular \"futuro real\" con el 20% más reciente:\n",
    "# df_nuevo = clientes.loc[clientes['FechaEvento_dt'] > cutoff].copy()\n",
    "# _ = score_future(df_nuevo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "---2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adabb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SHAPE crudo: (146939, 81)\n",
      ">>> Columnas (primeras 20): ['IdentificadorCliente', 'FechaEvento', 'UsabilidadCupo', 'CategoriaPrincipalCredito', 'DiasMaximosMoraCreditosGenerados', 'NumeroCreditosGPrevius', 'NumeroCreditosGCanalFPrevius', 'NumeroCreditosGEstadoActivosPrevius', 'NumeroCreditosGEstadoPagadosPrevius', 'NumeroCreditosGCanalVPrevius', 'NumeroCreditosLPrevius', 'NumeroCreditosLEstadoActivosPrevius', 'NumeroCreditosLEstadoPagadosPrevius', 'FechaVinculacionCliente', 'FechaPrimerUso', 'FechaUltimoUso', 'TotalPagosEfectuadosGlobalmentePrevius', 'TotalPagosEfectuadosLocalmentePrevius', 'CodigoAlmacenEntregaTC', 'CodigoMunicipioEntregaTC']\n",
      "\n",
      ">>> Construyendo features (sin fuga) ...\n",
      ">>> Sin columnas duplicadas en X.\n",
      ">>> Poda de columnas casi-constantes: ['Flag_Usab_NaN', 'Flag_Usab_Outlier', 'Flag_UltimoUsoPosterior', 'Flag_Edad_Out', 'Flag_Score_Negativo', 'Flag_DiasMaximosMoraCreditosGenerados_NaN', 'Flag_NumeroCreditosGPrevius_NaN', 'Flag_NumeroCreditosGCanalFPrevius_NaN', 'Flag_NumeroCreditosGCanalVPrevius_NaN', 'Flag_NumeroCreditosGEstadoActivosPrevius_NaN', 'Flag_NumeroCreditosGEstadoPagadosPrevius_NaN', 'Flag_NumeroCreditosLPrevius_NaN', 'Flag_NumeroCreditosLEstadoActivosPrevius_NaN', 'Flag_NumeroCreditosLEstadoPagadosPrevius_NaN', 'Flag_TotalPagosEfectuadosGlobalmentePrevius_NaN', 'Flag_TotalPagosEfectuadosLocalmentePrevius_NaN', 'Flag_NumeroIntentosFallidos_NaN', 'Flag_ScoreCrediticio_NaN', 'Flag_Edad_NaN', 'Flag_MesesDesdeVinculacion_NaN', 'Flag_MesesDesdePrimerUso_NaN', 'Flag_DiasDesdeUltimoUso_NaN', 'Flag_TotalPagosEfectuadosGlobalmentePrevius_Capped', 'Flag_TotalPagosEfectuadosLocalmentePrevius_Capped', 'Flag_NumeroCreditosGPrevius_Capped', 'Flag_NumeroCreditosGCanalFPrevius_Capped', 'Flag_NumeroCreditosGCanalVPrevius_Capped', 'Flag_NumeroCreditosGEstadoActivosPrevius_Capped', 'Flag_NumeroCreditosGEstadoPagadosPrevius_Capped', 'Flag_NumeroCreditosLPrevius_Capped', 'Flag_NumeroCreditosLEstadoActivosPrevius_Capped', 'Flag_NumeroCreditosLEstadoPagadosPrevius_Capped']\n",
      "\n",
      "=== Resumen columnas finales (previas al modelado) ===\n",
      "Numéricas: 26 | Categóricas: 7\n",
      "X shape: (146939, 33) | y rate (1): 0.226\n",
      "FechaEvento_dt rango: 2022-05-01 → 2023-10-31\n",
      "\n",
      ">>> Walk-forward CV (sin fuga):\n",
      "  - Split 1: train=(88163, 33), valid=(58776, 33), cutoff=2023-04-26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 399\u001b[0m\n\u001b[1;32m    396\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_final \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m    397\u001b[0m num_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_cols]\n\u001b[0;32m--> 399\u001b[0m logit_cv, hgb_cv \u001b[38;5;241m=\u001b[39m walk_forward_cv(clientes, X, y, cat_cols, num_cols)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLogit — Walk-forward CV:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28mprint\u001b[39m(logit_cv)\n",
      "Cell \u001b[0;32mIn[18], line 348\u001b[0m, in \u001b[0;36mwalk_forward_cv\u001b[0;34m(df, X, y, cat_cols, num_cols, cut_fracs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Split \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_tr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, valid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_va\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cutoff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd\u001b[38;5;241m.\u001b[39mTimestamp(c)\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Logit + calibración\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m logit\u001b[38;5;241m.\u001b[39mfit(X_tr, y_tr)\n\u001b[1;32m    349\u001b[0m cal_logit \u001b[38;5;241m=\u001b[39m CalibratedClassifierCV(logit, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    350\u001b[0m cal_logit\u001b[38;5;241m.\u001b[39mfit(X_va, y_va)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 416\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    368\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    371\u001b[0m     cloned_transformer,\n\u001b[1;32m    372\u001b[0m     X,\n\u001b[1;32m    373\u001b[0m     y,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    375\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m    671\u001b[0m         delayed(func)(\n\u001b[1;32m    672\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m    673\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    674\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    675\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m    676\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:472\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    470\u001b[0m fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit_transform(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\u001b[38;5;241m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_base.py:405\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_fit(\n\u001b[1;32m    401\u001b[0m             X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_fit(\n\u001b[1;32m    406\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[1;32m    407\u001b[0m     )\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_base.py:471\u001b[0m, in \u001b[0;36mSimpleImputer._dense_fit\u001b[0;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Median\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 471\u001b[0m     median_masked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmedian(masked_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# Avoid the warning \"Warning: converting a masked element to nan.\"\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     median \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mgetdata(median_masked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/ma/extras.py:735\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a, func\u001b[38;5;241m=\u001b[39m_median, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout,\n\u001b[1;32m    736\u001b[0m                 overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:3752\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3749\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3750\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3752\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/ma/extras.py:754\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m    752\u001b[0m         asorted \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 754\u001b[0m     asorted \u001b[38;5;241m=\u001b[39m sort(a, axis\u001b[38;5;241m=\u001b[39maxis, fill_value\u001b[38;5;241m=\u001b[39mfill_value)\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/ma/core.py:7012\u001b[0m, in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[1;32m   7009\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   7011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, MaskedArray):\n\u001b[0;32m-> 7012\u001b[0m     a\u001b[38;5;241m.\u001b[39msort(axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   7013\u001b[0m            endwith\u001b[38;5;241m=\u001b[39mendwith, fill_value\u001b[38;5;241m=\u001b[39mfill_value)\n\u001b[1;32m   7014\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7015\u001b[0m     a\u001b[38;5;241m.\u001b[39msort(axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/ma/core.py:5741\u001b[0m, in \u001b[0;36mMaskedArray.sort\u001b[0;34m(self, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[1;32m   5736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5738\u001b[0m sidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margsort(axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   5739\u001b[0m                     fill_value\u001b[38;5;241m=\u001b[39mfill_value, endwith\u001b[38;5;241m=\u001b[39mendwith)\n\u001b[0;32m-> 5741\u001b[0m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake_along_axis(\u001b[38;5;28mself\u001b[39m, sidx, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODELO DE RIESGO — VALIDACIÓN TEMPORAL ESTRICTA (SIN FUGA)\n",
    "# ============================================================\n",
    "# Requiere: pandas, numpy, scikit-learn, joblib\n",
    "# Supone que 'clientes' (crudo) está disponible en memoria.\n",
    "#   - columnas de fecha: FechaEvento, FechaVinculacionCliente, FechaUltimoUso, FechaPrimerUso\n",
    "#   - target: PerdidaCartera (0/1)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, brier_score_loss,\n",
    "                             classification_report, confusion_matrix, precision_recall_curve)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) CONFIG\n",
    "# -----------------------------\n",
    "TARGET = \"PerdidaCartera\"\n",
    "RANDOM_STATE = 42\n",
    "ARTIF_DIR = Path(\"./artifacts_modelo\"); ARTIF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# ============================================================\n",
    "# 1) INGESTA (usa tu carga real). Aseguramos target y forma.\n",
    "# ============================================================\n",
    "# EJEMPLO (descomenta si lo necesitas):\n",
    "# clientes = pd.read_parquet(\"data/clientes.parquet\")\n",
    "\n",
    "assert TARGET in clientes.columns, f\"No encuentro columna target '{TARGET}' en 'clientes'\"\n",
    "print(\">>> SHAPE crudo:\", clientes.shape)\n",
    "print(\">>> Columnas (primeras 20):\", list(clientes.columns)[:20])\n",
    "\n",
    "# ============================================================\n",
    "# 2) FEATURE ENGINEERING — SIN FUGA\n",
    "# ============================================================\n",
    "def parse_and_features(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # --- Fechas\n",
    "    df['FechaEvento_dt'] = (\n",
    "        pd.to_datetime(df['FechaEvento'], errors='coerce', utc=True)\n",
    "          .dt.tz_convert(None)\n",
    "    )\n",
    "    df['FechaVinculacionCliente_dt'] = pd.to_datetime(\n",
    "        df['FechaVinculacionCliente'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaUltimoUso_dt'] = pd.to_datetime(\n",
    "        df['FechaUltimoUso'], errors='coerce',\n",
    "        origin='1899-12-30', unit='D'\n",
    "    )\n",
    "    df['FechaPrimerUso_dt'] = pd.to_datetime(\n",
    "        df['FechaPrimerUso'], errors='coerce',\n",
    "        origin='1904-01-01', unit='D'\n",
    "    )\n",
    "\n",
    "    # Corrección conservadora PrimerUso\n",
    "    df['Flag_PrimerUsoAntesVinc'] = (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt']).astype(int)\n",
    "    mask_bad = df['FechaPrimerUso_dt'].isna() | (df['FechaPrimerUso_dt'] < df['FechaVinculacionCliente_dt'])\n",
    "    df.loc[mask_bad,  'FechaPrimerUso_corr'] = df.loc[mask_bad,  'FechaVinculacionCliente_dt']\n",
    "    df.loc[~mask_bad, 'FechaPrimerUso_corr'] = df.loc[~mask_bad, 'FechaPrimerUso_dt']\n",
    "\n",
    "    # Diferencias seguras\n",
    "    def safe_months(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d / 30.0\n",
    "\n",
    "    def safe_days(a, b):\n",
    "        d = (a - b).dt.days\n",
    "        d = d.where(d.notna(), 0); d = np.where(d < 0, 0, d)\n",
    "        return d\n",
    "\n",
    "    df['MesesDesdeVinculacion'] = safe_months(df['FechaEvento_dt'], df['FechaVinculacionCliente_dt'])\n",
    "    df['MesesDesdePrimerUso']   = safe_months(df['FechaEvento_dt'], df['FechaPrimerUso_corr'])\n",
    "    df['DiasDesdeUltimoUso']    = safe_days(df['FechaEvento_dt'],  df['FechaUltimoUso_dt'])\n",
    "\n",
    "    # --- Usabilidad\n",
    "    df['UsabilidadCupo'] = pd.to_numeric(df['UsabilidadCupo'], errors='coerce')\n",
    "    df['Flag_Usab_NaN']    = df['UsabilidadCupo'].isna().astype(int)\n",
    "    df['Flag_Usab_Outlier']= ((df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2)).astype(int)\n",
    "    df.loc[(df['UsabilidadCupo'] < 0) | (df['UsabilidadCupo'] > 2), 'UsabilidadCupo'] = np.nan\n",
    "    df['UsabilidadCupo']   = df['UsabilidadCupo'].fillna(df['UsabilidadCupo'].median())\n",
    "\n",
    "    # --- Flags de fechas\n",
    "    df['Flag_UltimoUsoPosterior'] = (df['FechaUltimoUso_dt'] > df['FechaEvento_dt']).fillna(False).astype(int)\n",
    "\n",
    "    # --- Numéricas con nulos —> flags + imputación conservadora\n",
    "    num_cols_candidates = [\n",
    "        'DiasMaximosMoraCreditosGenerados',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','CupoAprobado','ScoreCrediticio','Edad',\n",
    "        'MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso'\n",
    "    ]\n",
    "    for c in num_cols_candidates:\n",
    "        if c in df.columns:\n",
    "            df[f'Flag_{c}_NaN'] = df[c].isna().astype(int)\n",
    "            if c.startswith('NumeroCreditos') or c.startswith('TotalPagos'):\n",
    "                df[c] = df[c].fillna(0)\n",
    "            elif c in ['DiasMaximosMoraCreditosGenerados','Edad','NumeroIntentosFallidos']:\n",
    "                df[c] = df[c].fillna(0)\n",
    "\n",
    "    # --- Score & Cupo\n",
    "    df['ScoreSinInfo'] = (df['ScoreCrediticio'] == 0).astype(int)\n",
    "    if df['ScoreCrediticio'].isna().any():\n",
    "        med_pos = df.loc[df['ScoreCrediticio']>0, 'ScoreCrediticio'].median()\n",
    "        df['ScoreCrediticio'] = df['ScoreCrediticio'].fillna(med_pos)\n",
    "\n",
    "    df['log_CupoAprobado'] = np.log1p(df['CupoAprobado'])\n",
    "    df['log_CupoAprobado'] = df['log_CupoAprobado'].fillna(df['log_CupoAprobado'].median())\n",
    "\n",
    "    # --- Categóricas limpias\n",
    "    for c in ['CategoriaPrincipalCredito','UsoAppWeb','Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna('Desconocido')\n",
    "    df['Genero'] = df['Genero'].replace({27:'Desconocido'})\n",
    "    df['TipoMunicipioEntregaTC'] = df['TipoMunicipioEntregaTC'].replace({'PEQUEÃ‘O':'PEQUEÑO'}).fillna('Desconocido')\n",
    "\n",
    "    # --- Rango de Edad\n",
    "    df['Flag_Edad_Out'] = (~df['Edad'].between(18, 100, inclusive='both')).fillna(False).astype(int)\n",
    "    df.loc[df['Flag_Edad_Out']==1, 'Edad'] = np.nan\n",
    "    df['Edad'] = df['Edad'].fillna(df['Edad'].median())\n",
    "\n",
    "    # --- Features derivadas clave\n",
    "    if 'Flag_PrimerUsoTemu' not in df.columns and 'NumeroCreditosGPrevius' in df.columns:\n",
    "        df['Flag_PrimerUsoTemu'] = (df['NumeroCreditosGPrevius'] == 0).astype(int)\n",
    "\n",
    "    df['ratio_pagos_local_global'] = (\n",
    "        df['TotalPagosEfectuadosLocalmentePrevius'].fillna(0) /\n",
    "        (df['TotalPagosEfectuadosGlobalmentePrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    df['creditos_activos_ratio'] = (\n",
    "        df['NumeroCreditosGEstadoActivosPrevius'].fillna(0) /\n",
    "        (df['NumeroCreditosGPrevius'].fillna(0) + 1.0)\n",
    "    )\n",
    "    for c in ['ratio_pagos_local_global','creditos_activos_ratio']:\n",
    "        df[c] = df[c].replace([np.inf,-np.inf], np.nan).fillna(0).clip(0,1)\n",
    "\n",
    "    df['Flag_CanalVirtual'] = (\n",
    "        (df['CanalMunicipioEntregaTC'].astype(str).str.lower()=='virtual') |\n",
    "        (df['TipoMunicipioEntregaTC'].astype(str).str.upper()=='VIRTUAL')\n",
    "    ).astype(int)\n",
    "\n",
    "    # --- Score negativo -> 0, más bucket\n",
    "    df['Flag_Score_Negativo'] = (df['ScoreCrediticio'] < 0).astype(int)\n",
    "    df.loc[df['ScoreCrediticio'] < 0, 'ScoreCrediticio'] = 0\n",
    "\n",
    "    df['ScoreBucket'] = 'sin_info'\n",
    "    mask_pos = df['ScoreCrediticio'] > 0\n",
    "    if mask_pos.sum() > 0:\n",
    "        b1, b2 = df.loc[mask_pos, 'ScoreCrediticio'].quantile([0.33, 0.66]).values\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] <= b1), 'ScoreBucket'] = 'bajo'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b1) & (df['ScoreCrediticio'] <= b2), 'ScoreBucket'] = 'medio'\n",
    "        df.loc[mask_pos & (df['ScoreCrediticio'] >  b2), 'ScoreBucket'] = 'alto'\n",
    "    df['ScoreBucket'] = pd.Categorical(df['ScoreBucket'], categories=['sin_info','bajo','medio','alto'], ordered=True)\n",
    "\n",
    "    # --- Winsorización p99 + flags (colas largas)\n",
    "    def cap_with_flag(s, upper):\n",
    "        flag = (s > upper).astype(int)\n",
    "        return np.where(s > upper, upper, s), flag\n",
    "\n",
    "    cap_cols = [\n",
    "        'DiasDesdeUltimoUso','MesesDesdeVinculacion',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius'\n",
    "    ]\n",
    "    for c in cap_cols:\n",
    "        if c in df.columns:\n",
    "            p99 = df[c].quantile(0.99)\n",
    "            capped, flag = cap_with_flag(df[c].fillna(0), p99)\n",
    "            df[c] = capped\n",
    "            df[f'Flag_{c}_Capped'] = flag\n",
    "\n",
    "    # Agrupar categorías raras de CategoriaPrincipalCredito (<0.1%)\n",
    "    if 'CategoriaPrincipalCredito' in df.columns:\n",
    "        vc = df['CategoriaPrincipalCredito'].astype(str).value_counts(dropna=False)\n",
    "        cutoff = df.shape[0] * 0.001\n",
    "        rare_levels = vc[vc < cutoff].index\n",
    "        df['CategoriaPrincipalCredito'] = df['CategoriaPrincipalCredito'].astype(str)\n",
    "        df.loc[df['CategoriaPrincipalCredito'].isin(rare_levels), 'CategoriaPrincipalCredito'] = 'OtrosRare'\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_feature_lists(df: pd.DataFrame):\n",
    "    drop_from_features = [\n",
    "        'IdentificadorCliente','FechaEvento','FechaVinculacionCliente','FechaPrimerUso','FechaUltimoUso',\n",
    "        'FechaEvento_dt','FechaVinculacionCliente_dt','FechaPrimerUso_dt','FechaUltimoUso_dt','FechaPrimerUso_corr',\n",
    "        'CodigoAlmacenEntregaTC','CodigoAlmacenEntregaTC_str','AlmacenTop20',\n",
    "        'CodigoMunicipioEntregaTC','MunicipioCat','MunicipioTop20','MesCompra',\n",
    "        'DiasMora'\n",
    "    ]\n",
    "    num_base = [\n",
    "        'UsabilidadCupo','MesesDesdeVinculacion','MesesDesdePrimerUso','DiasDesdeUltimoUso',\n",
    "        'NumeroCreditosGPrevius','NumeroCreditosGCanalFPrevius','NumeroCreditosGCanalVPrevius',\n",
    "        'NumeroCreditosGEstadoActivosPrevius','NumeroCreditosGEstadoPagadosPrevius',\n",
    "        'NumeroCreditosLPrevius','NumeroCreditosLEstadoActivosPrevius','NumeroCreditosLEstadoPagadosPrevius',\n",
    "        'TotalPagosEfectuadosGlobalmentePrevius','TotalPagosEfectuadosLocalmentePrevius',\n",
    "        'NumeroIntentosFallidos','ScoreCrediticio','ScoreSinInfo','CupoAprobado','log_CupoAprobado','Edad',\n",
    "        'Flag_Usab_NaN','Flag_Usab_Outlier','Flag_PrimerUsoAntesVinc','Flag_UltimoUsoPosterior','Flag_Edad_Out',\n",
    "        'ratio_pagos_local_global','creditos_activos_ratio','Flag_Score_Negativo'\n",
    "    ]\n",
    "    num_dyn = [c for c in df.columns if c.startswith('Flag_') and (c.endswith('_NaN') or c.endswith('_Capped'))]\n",
    "    num_final = [c for c in (num_base + num_dyn) if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    cat_final = [\n",
    "        'Genero','TipoMunicipioEntregaTC','CanalMunicipioEntregaTC','UsoAppWeb','CategoriaPrincipalCredito',\n",
    "        'Flag_PrimerUsoTemu','ScoreBucket'\n",
    "    ]\n",
    "    cat_final = [c for c in cat_final if c in df.columns and c not in drop_from_features]\n",
    "\n",
    "    # --- Evitar solape entre num y cat + forzar unicidad y orden estable\n",
    "    overlap = set(num_final) & set(cat_final)\n",
    "    if overlap:\n",
    "        print(f\">>> Aviso: {len(overlap)} columnas estaban en num y cat. Se quitan de num: {sorted(overlap)}\")\n",
    "        num_final = [c for c in num_final if c not in overlap]\n",
    "\n",
    "    num_final = list(dict.fromkeys(num_final))\n",
    "    cat_final = list(dict.fromkeys(cat_final))\n",
    "    return num_final, cat_final\n",
    "\n",
    "\n",
    "def prune_low_variance(X: pd.DataFrame):\n",
    "    low_var = [c for c in X.columns if X[c].nunique(dropna=False) <= 1]\n",
    "    if low_var:\n",
    "        print(\">>> Poda de columnas casi-constantes:\", low_var)\n",
    "        return X.drop(columns=low_var, errors='ignore'), low_var\n",
    "    else:\n",
    "        print(\">>> Poda de columnas casi-constantes: ninguna\")\n",
    "        return X, []\n",
    "\n",
    "\n",
    "def build_pipelines(cat_cols, num_cols):\n",
    "    pre_logit = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "            ]), cat_cols),\n",
    "            ('num', Pipeline(steps=[\n",
    "                ('imp', SimpleImputer(strategy='median'))\n",
    "            ]), num_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    logit = Pipeline(steps=[\n",
    "        ('pre', pre_logit),\n",
    "        ('clf', LogisticRegression(\n",
    "            solver='saga', penalty='l2', class_weight='balanced',\n",
    "            max_iter=800, n_jobs=-1, random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pre_hgb = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "            ('num', 'passthrough', num_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    hgb = Pipeline(steps=[\n",
    "        ('pre', pre_hgb),\n",
    "        ('clf', HistGradientBoostingClassifier(\n",
    "            learning_rate=0.07, max_leaf_nodes=31, l2_regularization=1.0,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    return logit, hgb\n",
    "\n",
    "\n",
    "def evaluate_proba(y_true, y_proba, name=\"model\"):\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    ap  = average_precision_score(y_true, y_proba)\n",
    "    br  = brier_score_loss(y_true, y_proba)\n",
    "    print(f\"[{name}] ROC-AUC={auc:.3f} | PR-AUC={ap:.3f} | Brier={br:.3f}\")\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    j  = np.argmax(f1)\n",
    "    best_thr = thr[j-1] if j>0 and j-1 < len(thr) else 0.5\n",
    "    y_hat = (y_proba >= best_thr).astype(int)\n",
    "    print(f\"[{name}] best-F1={f1[j]:.3f} @ thr={best_thr:.3f}\")\n",
    "    print(f\"[{name}] ConfMatrix @thr={best_thr:.3f}:\\n\", confusion_matrix(y_true, y_hat))\n",
    "    print(f\"[{name}] Report @thr={best_thr:.3f}:\\n\", classification_report(y_true, y_hat, digits=3))\n",
    "    return dict(roc_auc=auc, pr_auc=ap, brier=br, thr=best_thr)\n",
    "\n",
    "\n",
    "def operating_points(y_true, y_proba, name=\"model\"):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    pts = {}\n",
    "    # máx F1\n",
    "    j = np.argmax(f1); pts['maxF1'] = (thr[j-1] if j>0 else 0.5, p[j], r[j], f1[j])\n",
    "    # precisión >= 0.6\n",
    "    idx = np.where(p>=0.6)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(r[idx])]\n",
    "        pts['prec>=0.6'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "    # recall >= 0.7\n",
    "    idx = np.where(r>=0.7)[0]\n",
    "    if len(idx)>0:\n",
    "        k = idx[np.argmax(p[idx])]\n",
    "        pts['rec>=0.7'] = (thr[k-1] if k>0 else 0.5, p[k], r[k], f1[k])\n",
    "\n",
    "    print(f\"\\n[{name}] Puntos de operación sugeridos:\")\n",
    "    for kk,(t,pp,rr,ff) in pts.items():\n",
    "        print(f\" - {kk:10s}: thr={t:.3f} | precision={pp:.3f} | recall={rr:.3f} | F1={ff:.3f}\")\n",
    "    return pts\n",
    "\n",
    "\n",
    "def walk_forward_cv(df, X, y, cat_cols, num_cols, cut_fracs=(0.6,0.7,0.8)):\n",
    "    \"\"\"Valida SIN FUGA con 3 cortes temporales (ajustable).\"\"\"\n",
    "    cutoffs = df['FechaEvento_dt'].quantile(list(cut_fracs)).values\n",
    "    rows_l, rows_h = [], []\n",
    "    logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "\n",
    "    print(\"\\n>>> Walk-forward CV (sin fuga):\")\n",
    "    for i, c in enumerate(cutoffs, 1):\n",
    "        tr_idx = df['FechaEvento_dt'] <= c\n",
    "        va_idx = df['FechaEvento_dt'] >  c\n",
    "        X_tr, X_va = X.loc[tr_idx], X.loc[va_idx]\n",
    "        y_tr, y_va = y.loc[tr_idx], y.loc[va_idx]\n",
    "        print(f\"  - Split {i}: train={X_tr.shape}, valid={X_va.shape}, cutoff={pd.Timestamp(c).date()}\")\n",
    "\n",
    "        # Logit + calibración\n",
    "        logit.fit(X_tr, y_tr)\n",
    "        cal_logit = CalibratedClassifierCV(logit, method='sigmoid', cv='prefit')\n",
    "        cal_logit.fit(X_va, y_va)\n",
    "        proba_l = cal_logit.predict_proba(X_va)[:,1]\n",
    "        m_l = evaluate_proba(y_va, proba_l, name=f\"Logit+Cal (WF{i})\")\n",
    "        rows_l.append({\"cutoff\": c, **m_l})\n",
    "\n",
    "        # HGB + sample_weight + calibración\n",
    "        sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "        hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "        cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "        cal_hgb.fit(X_va, y_va)\n",
    "        proba_h = cal_hgb.predict_proba(X_va)[:,1]\n",
    "        m_h = evaluate_proba(y_va, proba_h, name=f\"HGB+Cal (WF{i})\")\n",
    "        rows_h.append({\"cutoff\": c, **m_h})\n",
    "\n",
    "    return pd.DataFrame(rows_l), pd.DataFrame(rows_h)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) CONSTRUIR DATASET LIMPIO + LISTAS DE FEATURES\n",
    "# ============================================================\n",
    "print(\"\\n>>> Construyendo features (sin fuga) ...\")\n",
    "clientes = parse_and_features(clientes)\n",
    "num_final, cat_final = build_feature_lists(clientes)\n",
    "\n",
    "X = clientes[num_final + cat_final].copy()\n",
    "y = clientes[TARGET].astype(int).copy()\n",
    "\n",
    "# --- FIX CRÍTICO: ELIMINAR COLUMNAS DUPLICADAS EN X ---\n",
    "dups_mask = X.columns.duplicated(keep='first')\n",
    "if dups_mask.any():\n",
    "    dups = pd.Series(X.columns)[dups_mask].tolist()\n",
    "    print(f\">>> Columnas duplicadas detectadas y removidas ({len(dups)}): {dups}\")\n",
    "    X = X.loc[:, ~X.columns.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\">>> Sin columnas duplicadas en X.\")\n",
    "\n",
    "X, dropped_lowvar = prune_low_variance(X)\n",
    "\n",
    "print(\"\\n=== Resumen columnas finales (previas al modelado) ===\")\n",
    "print(f\"Numéricas: {len([c for c in X.columns if c in num_final])} | Categóricas: {len([c for c in X.columns if c in cat_final])}\")\n",
    "print(\"X shape:\", X.shape, \"| y rate (1):\", y.mean().round(3))\n",
    "print(\"FechaEvento_dt rango:\", str(clientes['FechaEvento_dt'].min().date()), \"→\", str(clientes['FechaEvento_dt'].max().date()))\n",
    "\n",
    "# ============================================================\n",
    "# 4) WALK-FORWARD CV — SIN MIRAR EL FUTURO\n",
    "# ============================================================\n",
    "cat_cols = [c for c in cat_final if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "logit_cv, hgb_cv = walk_forward_cv(clientes, X, y, cat_cols, num_cols)\n",
    "\n",
    "print(\"\\nLogit — Walk-forward CV:\")\n",
    "print(logit_cv)\n",
    "print(f\"Logit — medias: ROC-AUC={logit_cv.roc_auc.mean():.3f} | PR-AUC={logit_cv.pr_auc.mean():.3f} | Brier={logit_cv.brier.mean():.3f}\")\n",
    "\n",
    "print(\"\\nHGB — Walk-forward CV:\")\n",
    "print(hgb_cv)\n",
    "print(f\"HGB — medias:   ROC-AUC={hgb_cv.roc_auc.mean():.3f} | PR-AUC={hgb_cv.pr_auc.mean():.3f} | Brier={hgb_cv.brier.mean():.3f}\")\n",
    "\n",
    "chosen = \"HGB\" if hgb_cv.pr_auc.mean() >= logit_cv.pr_auc.mean() else \"Logit\"\n",
    "print(f\"\\n>>> Modelo elegido por PR-AUC medio: {chosen}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5) HOLDOUT FINAL (FUTURO) — 20% MÁS RECIENTE\n",
    "# ============================================================\n",
    "cutoff = clientes['FechaEvento_dt'].quantile(0.8)\n",
    "train_idx = clientes['FechaEvento_dt'] <= cutoff\n",
    "hold_idx  = clientes['FechaEvento_dt'] >  cutoff\n",
    "X_tr, X_ho = X.loc[train_idx], X.loc[hold_idx]\n",
    "y_tr, y_ho = y.loc[train_idx], y.loc[hold_idx]\n",
    "print(f\"\\n>>> Holdout temporal: train={X_tr.shape}, holdout={X_ho.shape}, corte={pd.Timestamp(cutoff).date()}\")\n",
    "\n",
    "logit, hgb = build_pipelines(cat_cols, num_cols)\n",
    "\n",
    "# LOGIT + calibración\n",
    "logit.fit(X_tr, y_tr)\n",
    "cal_logit = CalibratedClassifierCV(logit, method='sigmoid', cv='prefit')\n",
    "cal_logit.fit(X_ho, y_ho)\n",
    "proba_logit = cal_logit.predict_proba(X_ho)[:,1]\n",
    "_ = evaluate_proba(y_ho, proba_logit, name=\"HOLDOUT-Logit\")\n",
    "operating_points(y_ho, proba_logit, name=\"HOLDOUT-Logit\")\n",
    "\n",
    "# HGB + sample_weight + calibración\n",
    "sw = compute_sample_weight(\"balanced\", y_tr)\n",
    "hgb.fit(X_tr, y_tr, clf__sample_weight=sw)\n",
    "cal_hgb = CalibratedClassifierCV(hgb, method='isotonic', cv='prefit')\n",
    "cal_hgb.fit(X_ho, y_ho)\n",
    "proba_hgb = cal_hgb.predict_proba(X_ho)[:,1]\n",
    "m_hold = evaluate_proba(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "operating_points(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# Guardar bundle de artefactos\n",
    "bundle = {\n",
    "    \"model_calibrado\": cal_hgb if chosen==\"HGB\" else cal_logit,\n",
    "    \"chosen\": chosen,\n",
    "    \"num_final\": num_final,\n",
    "    \"cat_final\": cat_final,\n",
    "    \"columns_after_prune\": list(X.columns),\n",
    "    \"cutoff\": cutoff\n",
    "}\n",
    "joblib.dump(bundle, ARTIF_DIR/\"modelo_calibrado.joblib\")\n",
    "print(f\"\\n>>> Artefactos guardados en {ARTIF_DIR/'modelo_calibrado.joblib'}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6) (OPCIONAL) CALIBRACIÓN POR DECILES EN HOLDOUT\n",
    "# ============================================================\n",
    "def decile_calibration(y_true, y_proba, name=\"holdout\"):\n",
    "    bins = pd.qcut(y_proba, q=10, duplicates='drop')\n",
    "    tab = pd.DataFrame({\"p\":y_proba, \"y\":y_true}).groupby(bins, observed=True).agg(\n",
    "        p_mean=('p','mean'),\n",
    "        y_rate=('y','mean'),\n",
    "        n=('p','size')\n",
    "    ).reset_index().rename(columns={\"p\":\"bin\"})\n",
    "    print(f\"\\n[{name}] Calibración por deciles (p_mean vs y_rate):\")\n",
    "    print(tab.to_string(index=False))\n",
    "    return tab\n",
    "\n",
    "_ = decile_calibration(y_ho, proba_hgb, name=\"HOLDOUT-HGB\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) (OPCIONAL) FUNCIÓN DE SCORING FUTURO\n",
    "# ============================================================\n",
    "def score_future(df_nuevo_raw: pd.DataFrame, artif_path=ARTIF_DIR/\"modelo_calibrado.joblib\", target_col=TARGET):\n",
    "    \"\"\"Aplica el mismo pipeline a df_nuevo. Si trae label, evalúa; si no, solo predice.\"\"\"\n",
    "    bundle = joblib.load(artif_path)\n",
    "    model  = bundle[\"model_calibrado\"]\n",
    "    cols_ok = bundle[\"columns_after_prune\"]\n",
    "    num_final, cat_final = bundle[\"num_final\"], bundle[\"cat_final\"]\n",
    "\n",
    "    df_nuevo = parse_and_features(df_nuevo_raw)\n",
    "    Xn = df_nuevo[num_final + cat_final].copy()\n",
    "    # Alinear columnas esperadas + deduplicar por si acaso\n",
    "    Xn = Xn.reindex(columns=cols_ok, fill_value=np.nan)\n",
    "    Xn = Xn.loc[:, ~Xn.columns.duplicated(keep='first')]\n",
    "    proba = model.predict_proba(Xn)[:,1]\n",
    "\n",
    "    if target_col in df_nuevo.columns:\n",
    "        y_true = df_nuevo[target_col].astype(int)\n",
    "        _ = evaluate_proba(y_true, proba, name=\"DF_NUEVO\")\n",
    "        operating_points(y_true, proba, name=\"DF_NUEVO\")\n",
    "        _ = decile_calibration(y_true, proba, name=\"DF_NUEVO\")\n",
    "    else:\n",
    "        print(\"df_nuevo sin target: se devuelven solo probabilidades.\")\n",
    "    out = pd.DataFrame({\"proba_perdida\": proba})\n",
    "    out_path = ARTIF_DIR/\"scoring_df_nuevo.csv\"\n",
    "    out.to_csv(out_path, index=False)\n",
    "    print(f\"Scoring exportado a {out_path}\")\n",
    "    return out\n",
    "\n",
    "# ------------- QUICK TEST -------------\n",
    "# Simular \"futuro real\" con el 20% más reciente (ya evaluado arriba):\n",
    "# df_nuevo = clientes.loc[clientes['FechaEvento_dt'] > cutoff].copy()\n",
    "# _ = score_future(df_nuevo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d5a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44eaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
